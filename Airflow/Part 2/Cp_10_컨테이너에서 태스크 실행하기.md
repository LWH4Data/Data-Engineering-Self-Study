<ul>
  <li>
    Airflow 배포 관리와 관련된 몇 가지 문제를 파악하기.
  </li>
  <li>
    컨테이너 접근 방식이 Airflow 배포를 단순화하는 데 어덯게 도움이 되는지 검토하기
  </li>
  <li>
    도커의 Airflow에서 컨테이너화된 태스크 실행하기
  </li>
  <li>
    컨테이너화된 DAG 개발에서 워크플로에 대한 전반적인 개요 수립하기.
  </li>
</ul>

<br>

<h1>1. 다양한 오퍼레이터를 쓸 때 고려해야 할 점</h1>
<h2>1-1. 오퍼레이터 인터페이스 및 구현하기</h2>
<ul>
  <li>
    서로 다른 오퍼레이터를 사용할 때 어려운 점은 효율적인 구성을 위해 <strong>각 오퍼레이터별</strong> 인터페이스와 내부 동작에 익숙해져야 한다는 점이다.
  </li>
</ul>

<br>

<h2>1-2. 복잡하며 종속성이 충돌하는 환경</h2>
<ul>
  <li>
    다양한 오퍼레이터를 사용할 때 또 다른 어려운 점은 오퍼레이터마다 <strong>각각의 종속성</strong>을 요구한다는 것이다.
  </li>
  <li>
    모든 종속성은 Airflow 스케줄러 뿐만 아니라 <strong>Airflow 워커</strong> 자체에도 설치되어야 한다.
  </li>
</ul>

<br>

<h2>1-3. 제네릭 오퍼레이터 지향하기</h2>
<ul>
  <li>
    Airflow 태스크를 실행하기 위해 <strong>하나의 제너릭 오퍼레이터</strong>를 사용하는 것을 의미한다.
  </li>
  <li>
    한 가지 종류의 <strong>오퍼레이터</strong>, 한 가지 유형의 <strong>태스크</strong> 그리고 하나의 Airflow <strong>종속성 집합</strong>만 관리하면 되기에 편하다.
  </li>
  <li>
    각각에 대한 종속성 패키지를 설치하고 관리하지 않고도 동시에 다양한 태스크를 수행할 수 있는 제네릭 오퍼레이터는 <strong>도커</strong>로 구현 가능하다.
  </li>
</ul>

<br><br>

<h1>2 ~ 3. Docker</h1>
<ul>
  <li>
    Docker와 관련된 내용이기에 생략한다.
  </li>
</ul>

<br><br>

<h1>4. 도커에서 태스크 실행하기</h1>
<h2>4-1. DockerOperator 소개</h2>
<ul>
  <li>
    Airflow로 컨테이너에서 태스크를 실행하는 가장 쉬운 방법은 apache-airflow-providers-docker 공급자 패키지의 <strong>DockerOperator</strong>를 사용하는 것이다.
  </li>
  <li>
    순서는 아래와 같다.
  </li>
    <ul>
      <li>
        Airflow가 worker에게 태스크를 스케줄하여 실행하도록 한다.
        <br>→ DockerOperator는 적절한 인수를 사용해 워커 시스템에 docker run명령을 실행.
        <br>→ 도커 데몬이 이미지 레지스트리에 필요한 <strong>도커 이미지</strong>를 가져온다.
        <br>→ 도커 이미지를 실행하는 <strong>컨테이너를 생성</strong>한다.
        <br>→ 로컬 볼륨을 컨테이너에 <strong>바인드 마운트</strong>한다.
        <br>→ 명령이 완료된 후 컨테이너는 종료되고 DockerOperator는 Airflow 워커 <strong>결과를 반환</strong>.
      </li>
    </ul>
</ul>

```python
# 1. DockerOperator를 사용하는 예제
rank_movie = DockerOperator(
    # Airflow에서 이 작업(task)을 구분할 고유 ID
    task_id="rank_movies",
    # 실행할 Docker 이미지 이름
    #     - 영화 평점을 처리하는 Python 스크립트를 포함.
    image="manning-airflow/movielens-ranking",
    # 컨테이너 실행 시 전달할 명령어 (리스트 형태)
    command=[
        "rank_movies.py",               # 실행할 Python 스크립트
        "--input_path",                 # 입력 파일 경로 인자 이름
        "/data/ratings/{{ ds }}.json",  # 입력 파일 경로 (Jinja 템플릿 사용)
        "--output_path",                # 출력 파일 경로 인자 이름
        "/data/rankings/{{ ds }}.csv",  # 출력 파일 경로 (동일 날짜로 저장)
    ],
    # 바인드 마운트
    volumes=["/tmp/airflow/data:/data"],
)
```

<br>

<h2>4-2. 태스크를 위한 컨테이너 이미지 생성하기</h2>
<ul>
  <li>
    태스크 실행에 필요한 종속성을 확인하고 <strong>Dockerfile</strong>과 docker build 명령어를 통해 필요한 <strong>이미지를 생성</strong>한다.
  </li>
</ul>

```python
# 1. click 라이브러리를 기반으로하는 파이썬 CLI 스크립트의 기본구성.

# 로그 출력을 위한 표준 라이브러리
import logging
# CLI(Command Line Interface) 생성을 쉽게 도와주는 라이브러리
import click

# logging 설정: INFO 레벨 이상의 로그 메시지를 출력하도록 설정
logging.basicConfig(level=logging.INFO)

# @click.command() 데코레이터:
#    - 이 함수(main)를 하나의 CLI 명령어로 등록한다는 의미.
@click.command()

# @click.option():
#     - CLI 실행 시 사용할 옵션(= 명령줄 인자)을 정의.
@click.option(
    # CLI에서 입력받을 옵션 이름 (예: --start_date 2025-10-04)
    "--start_date",
    # 입력 형식을 지정 (YYYY-MM-DD 형태의 날짜)
    type=click.DateTime(formats=["%Y-%m-%d"]),
    # 필수 입력값으로 지정
    required=True,
    # --help 옵션 실행 시 표시될 설명 문구
    help="Start date for ratings.",
)
@click.option(
    """ 중략 """
)
@click.option(
    """ 중략 """
)
""" 중략 """

# 옵션은 main 함수에 키워드 인수로 전달된다.
def main(start_date, ...):
    """CLI script for fetching ratings from the movielens API."""

# 스크립트 실행 시 main 함수/명령이 호출되도록 하는 파이썬 규칙.
if __name__ == "__main__":
    main()
```

```python
# 2. 스케폴딩을 사용하여 8장 시작과 동일한 논리로 main 함수 작성.

# click에 대한 다른 CLI 인수를 정의. (생략).
'''
from pathlib import Path

@click.command()
@click.option(...)
'''

def main(start_date, end_date, output_path, host, user, password, batch_size):

    """CLI cript for fetching ratings from the movielens API."""

    # HTTP 요청을 수행하기 위해 올바른 인증 세부 정보로 세션 정보 설정.
    session = requests.Session()
    session.auth = (user, password)

    # 로깅은 사용자에게 피드백을 제공하는 용도로 사용.
    logging.info("Fetching ratings from %s (user: %s)", host, user)

    # 제공된 세션으로 _get_ratings 함수를 사용해 평점을 가져온다.
    ratings = list(
        _get_ratings(
            session=session,
            host=host,
            start_date=start_date,
            end_date=end_date,
            batch_size=batch_size,
        )
    )
    logging.info("Retrieved %d ratings!", len(ratings))
    
    output_path = Path(output_path)

    output_dir = output_path.parent

    # 출력 디렉터리가 있는지 확인.
    output_dir = output_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)
    logging.info("Writing to %s", output_path)

    # 출력 디렉터리에 JSON 형식으로 저장.
    with output_path.open("w") as file_:
        json.dump(ratings, file_)
```

```dockerfile
# 3. 이미지 빌드를 위한 Dockerfile 작성.
FROM python:3.8-slim

# 필요한 종속성 설치
RUN pip install click==7.1.1 requests==2.23.0

# fetch_ratings 스크립트를 복사하고 실행 가능하게 만든다.
COPY scripts/fetch_ratings.py /usr/bin/local/fetch-rating

RUN chmod +x /usr/bin/local/fetch-ratings
#스크립트가 PATH에 있는지 확인한다.
ENV PATH="/usr/local/bin:${PATH}"
```

<br>

<h2>4-3. 도커 태스크로 DAG 구성하기</h2>
<ul>
  <li>
    도커 기반 DAG를 작성하는 방법은 <strong>DockerOperator</strong>로 기존 태스크를 대체하고 올바른 인수로 태스크를 실행하도록 하면 된다.
  </li>
  <li>
    컨테이너는 태크스가 작업이 끝나면 존재하지 않기에 태스크 간 <strong>데이터를 교환</strong>하는 방법도 고려해야 한다.
  </li>
</ul>

```python
# 1. 평점 가져오기 컨테이너 실행.
import os
import datetime as dt

from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator

# DAG 정의
with DAG(
    dag_id="01_docker",
    description="Fetches ratings from the Movielens API using Docker.",
    start_date=dt.datetime(2019, 1, 1),
    end_date=dt.datetime(2019, 1, 3),
    schedule_interval="@daily",
) as dag:
    fetch_ratings = DockerOperator(
        task_id="fetch_ratings",
        # DockerOperator에서 movielens-fetch 이미지를 사용하도록 지시.
        image="manning-airflow/movielens-fetch",
        # 필수 인수를 사용하여 컨테이너에서 fetch-ratings 스크립트를 실행.
        command=[
            "fetch-ratings",
            "--start_date", "{{ ds }}",
            "--end_date", "{{ next_ds }}",
            "--output_path", "/data/ratings/{{ ds }}.json",
            "--user", 
            # API에 대한 호스트 및 인증 세부 정보를 제공.
            os.environ["MOVIELENS_USER"],
            "--password", 
            os.environ["MOVIELENS_PASSWORD"],
            "--host", 
            os.environ["MOVIELENS_HOST"],
        ],
        # 데이터를 저장할 볼륨을 마운트. (호스트 경로는 Docker 호스트에 있다).
        volumes=["/tmp/airflow/data:/data"],
        # 컨테이너가 airflow 도커 네트워크에 연결하면 API를 호출할 수 있다.
        network_mode="airflow",
        auto_remove=True,
    )
```

```python
# 2. DAG에 랭킹 태스크를 추가.
rank_movies = DockerOperator(
    task_id="rank_movies",
    # movielens-ranking 이미지를 사용.
    image="manning-airflow/movielens-ranking",
    # 필요한 입/출력 경로롤 rank-movies 스크립트를 호출
    command=[
        "rank-movies",
        "--input_path",
        "/data/ratings/{{ ds }}.json",
        "--output_path",
        "/data/rankings/{{ ds }}.csv",
    ],
    volumes=["/tmp/airflow/data:/data"],
)
fetch_ratings >> rank_movies
```

<br>

<h2>4-4. 도커 기반의 워크플로</h2>
<ul>
  <li>
    도커 기반 워크플로의 가장 큰 특징은 <strong>도커 컨테이터</strong>를 먼저 만들어야 한다는 것이며 일반적으로 다음과 같은 단계를 거친다.
  </li>
    <ul>
      <li>
        개발자는 필요한 이미지에 대한 <strong>도커파일</strong>을 만들고 이미지를 작성하도록 지시 한다.
        <br>→ 도커 데몬은 개발 머신에 해당하는 <strong>이미지를 구축</strong>한다.
        <br>→ 도커 데몬은 이미지를 나중에 사용할 수 있도록 <strong>컨테이너 레지스트리에 게시</strong>한다.
        <br>→ 개발자는 빌드 이미지를 참조하는 <strong>DockerOperator</strong>를 사용하여 <strong>DAG를 작성</strong>한다.
        <br>→ DAG가 활성화된 후 Airflow는 <strong>DAG를 실행</strong>하고 <strong>DockerOperator 태스크를 스케줄</strong> 한다.
        <br>→ Airflow worker는 <strong>DockerOperator 태스크를 선택</strong>하고 컨테이너 레지스트리에서 <strong>필요한 이미지</strong>를 가져온다.
        <br>→ 각 태스크를 위해 Airflow worker는 worker에 설치된 도커 데몬을 사용하여 <strong>해당 이미지와 인수로 컨테이너를 실행</strong>한다.
      </li>
    </ul>
</ul>

<br><br>

<h1>5. 쿠버네티스에서 태스크 실행</h1>
<ul>
  <li>
    도커는 컨테이너화된 태스크를 <strong>단일 시스템</strong>에서 실행할 수 있지만 <strong>여러 시스템</strong>에서 태스크를 조정하고 분산하는 데에는 <strong>쿠버네티스(Kubernetes)</strong>와 같은 컨테이너 오케스트레이션 시스템을 활용한다.
  </li>
</ul>

<br>

<h2>5-1. 쿠버네티스 소개</h2>
<ul>
  <li>
    쿠버네티스는 도커에 비해 컨테이너를 <strong>여러 작업 노드</strong>에 배치해 관리하여 확장할 수 있도록 지원한다.
  </li>
  <li>
    쿠버네티스는 스케줄링 시에 필요한 <strong>리소스, 스토리지 및 특수한 하드웨어</strong> 요구사항 등을 고려한다.
  </li>
  <li>
    쿠버네티스는 기본적으로 <strong>마스터</strong>와 <strong>노드</strong> 두 가지 주요 구성요로가 존재한다.
  </li>
    <ul>
      <li>
        <strong>마스터 노드</strong>
      </li>
        <ul>
          <li>
            API 서버, 스케줄러 및 배포, 스토리지 등을 관리하는 기타 서비스를 포함한 <strong>다양한 컴포넌트를 실행</strong>한다.
          </li>
          <li>
            쿠버네티스 API 서버는 kubectl(쿠버네티스 기본 CLI) 또는 쿠버네티스 파이썬 SK와 같은 <strong>클라이언트</strong>에서 쿠버네티스를 쿼리하고 명령을 실행하여 <strong>컨테이너를 배포</strong>한다.
          </li>
          <li>
            쿠버네티스 <strong>클러스터에서 컨테이너화된 앱을 관리</strong>하는 주요 포인트이다.
          </li>
        </ul>
      <li>
        <strong>워커 노드</strong>
      </li>
        <ul>
          <li>
            스케줄러가 할당한 <strong>컨테이너 앱을 실행</strong>한다.
          </li>
          <li>
            쿠버네티스에서 이런 앱을 <strong>파드(pod)</strong>라고 하며 단일 시스템에서 <strong>함께 실행해야 하는 컨테이너</strong>가 <strong>하나 이상 포함</strong>된다.
          </li>
          <li>
            파드는 쿠버네티스의 가장 작은 단위이며 Airflow 태스크는 단일 파드 내부의 컨테이너로 실행된다.
          </li>
        </ul>
    </ul>
  <li>
    쿠버네티스는 보안 및 스토리지 관리를 위한 <strong>내장된 기본 기능</strong>을 제공한다. 
  </li>
</ul>

<br>

<h2>5-2. 쿠버네티스 설정하기</h2>
<ul>
  <li>
    쿠버네티스 설치는 <strong>로컬</strong>에 직접 설치하거나 <strong>클라우드 환경</strong>에 설치할 수 있다.
  </li>
</ul>

```bash
# 1. 쿠버네티스 설치 확인.
kubectl cluster-info
```

```bash
# 2. 쿠버네티스 네임스페이스 생성.
#   - Airflow 관련 리소스 및 태스크 파드 포함할 것임.
kubectl create namespace airflow
```

```yaml
# 3. 스토리지를 위한 YAML 명세서.
# (kubernetes/resources/data-volume.yaml)

apiVersion: v1
# 영구 볼륨을 정의하기 위한 쿠버네티스 명세.
# 가상 디스크로 파드에 데이터 저장 공간을 제공한다.
kind: PersistentVolume
metadata:
  # 볼륨에 할당할 이름.
  name: data-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    # 볼륨의 크기
    storage: 1Gi
  # 한 번에 하나의 컨테이너 읽기/쓰기 액세스 허용
  accessModes:
    - ReadWriteOnce
  hostPath:
    # 스토리지가 보관될 호스트의 파일 경로를 지정.
    path: "/tmp/data"

---
apiVersion: v1
# 특정 볼륨 내에서 일부 스토리지를 예약하여 영구 볼륨을 할당 하기위한 쿠버네티스 스펙.
kind: PersistentVolumeClaim
metadata:
  # 스토리지 공간을 할당할 볼륨의 이름.
  name: data-volume
spec:
  storageClassName: manual
  # 스토리지 할당을 허용하는 액세스 모드
  accessModes:
    - ReadWriteOnce:
  resources:
    requests:
      # 스토리지 할당 크기.
      storage: 1Gi
```

```bash
# 4. kubectl을 사용하여 스토리지 리소스 배포.
kubectl --namespace airflow aply -f resources/data-volume.yaml
```

```yaml
# 5. API에 대한 YAML 명세서.
# (kubernetes/resources/api.yaml)

apiVersion: apps/v1
# 컨테이너 배포 생성을 위한 쿠버네티스 명세
kind: Deployment
metadata:
  # 배포 이름
  name: movielens-deployment
  # 배포용 레이블(서비스에서 일치)
  labels:
    app: movielens
spec:
  replicas: 1
selector:
  matchLabels:
    app: movielens
template:
  metadata:
    labels:
      app: movielens
  spec:
    # 각각의 포트, 환경 변수 등 배포에 포함할 컨테이너를 지정.
    containers:
    - name: movielens
      # 쿠버네티스에게 최신 버전의 movielens-api 이미지를 사용하도록 지시.
      image: manning-airflow/movielens-api
      prots:
      - containerPort: 5000
      env:
      - name: API_USER
        value: airflow
      - name: API_PASSWORD
        value: airflow

---

# 주어진 배포에 연결할 수 있는 서비스 생성을 위한 쿠버네티스 명세
apiVersion: v1
kind: Service
metadata:
  name: movielens
spec:
  # 서비스를 배포에 연결하기 위해 배포의 레이블과 일치하는 셀렉터
  selector:
    app: movielens
spec:
  selector:
    app: movielens
  ports:
  # 서비스 포트(80)를 배포 컨테이너의 포트(5000)에 매핑.
  - protocol: TCP
    port: 80
    targetPort: 5000
```

```bash
# 6. Movielens API 배포.
kubectl --namespace airflow apply -f resources/api.yaml
```

```bash
# 7. 결과 확인.
kubectl --namespace airflow get pods
kubgecl --namespace airflow port-forward svc/movielens 8000:80
```

<br>

<h2>5-3. KubernetesPodOperator</h2>
<ul>
  <li>
    쿠버네티스에서 태스크를 실행하기 위해서는 DockerOperator를 apacheairflow-providers-cncf-kubernetes 공급 패키지에서 사용할 수 있는 <strong>KubernetesPodOperator의 인스턴스</strong>로 교체해야 한다.
  </li>
</ul>

```python
# 1. KubernetesPodOperator 사용하기.
fetch_ratings = KubernetesPodOperator(
    task_id="fetch_ratings",
    # 사용할 이미지
    image="manning-airflow/movielens-fetch",
    # 컨테이너 내부에서 실행할 파일
    cmds=["fetch-ratings"],
    # 실행 파일에 전달할 인수
    arguments=[
        "--start_date",
        "{{ ds }}",
        "--end_date",
        "{{ next_ds }}",
        "--output_path",
        "/data/ratings/{{ ds }}.json",
        "--user",
        os.environ["MOVIELENS_USER"],
        "--password",
        os.environ["MOVIELENS_PASSWORD"],
        "--host",
        os.environ["MOVIELENS_HOST"],
    ],
    # 파드를 실행할 쿠버네티스 네임스페이스
    namespace="airflow",
    # 파드에 사용할 이름.
    name="fetch--ratings",
    # 사용할 클러스터 이름
    cluster_context="docker-desktop",
    # 쿠버네티스 내에서 Airflow 자체를 실행하지 않음을 지정.
    in_cluster=False,
    # 파드에서 사용할 볼륨 및 볼륨 마운트
    volumes=[volume],
    volume_mounts=[volume_mount],
    # 로컬에서 빌드된 이미지를 사용하도록 지정.
    image_pull_policy="Never",
    # 실행이 끝나면 자동 파드 삭제.
    is_delete_operator_pod=True,
)
```

```python
# 2. 볼륨 및 볼륨 마운트
from kubernetes.client import models as k8s

""" 중략 """

# 이전에 생성된 스토리지 볼륨 및 할당에 대한 참조.
volume_claim = k8s.V1PersistentVolumeClaimVolumeSource(
    claim_name="data-volume"
)

# 상단의 볼륨 참조.
volume = k8s.V1Volume(
    name="data-volume",
    persistent_volume_claim=volume_claim
)
volume_mount = k8s.V1VolumeMount(
    name="data-volume",
    # 볼륨을 마운트할 위치
    mount_path="/data",
    sub_path=None,
    # 쓰기 불가능한 볼륨으로 마운트.
    read_only=False,
)
```

```python
# 3. 영화 랭킹 태스크 추가.
    rank_movie = KubernetesPodOperator(
        task_id="rank_movies",
        image="manning-airflow/movielens-rank",
        cmds=["rank-movies"],
        arguments=[
            "--input_path",
            "/data/ratings/{{ ds }}.json",
            "--output_path",
            "/data/rankings/{{ ds }}.csv",
        ],
        namespace="airflow",
        name="fetch-ratings",
        cluster_context="docker-desktop",
        in_cluster=False,
        volumes=[volume],
        volume_mounts=[volume_mount],
        image_pull_policy="Never",
        is_delete_operator_pod=True,
    )
```

```python
# 4. 전체 DAG 구현.
import datetime as dt
import os

from kubernetes.client import models as k8s

from airflow import DAG
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import (
    KubernetesPodOperator,
)

with DAG(
    dag_id="02_kubernetes",
    description="Fetches ratings from the Movielens API using kubernetes.",
    start_date=dt.datetime(2019, 1, 1),
    end_date=dt.datetime(2019, 1, 3),
    schedule_interval="@daily",
) as dag:
    volume_claim = k8s.V1PersistentVolumeClaimVolumeSource(...)
    volume = k8s.V1Volume(...)
    volume_mount = k8s.V1VolumeMount(...)

    fetch_ratings = KubernetesPodOperator(...)
    rank_moives = KubernetesPodOperator(...)

    fetch_ratings >> rank_movies
```

<br>

<h2>5-4. 쿠버네티스 관련 문제 진단하기</h2>
<ul>
  <li>
    문제가 발생하면 태스크가 올바르게 끝나지 않고 실행 상태로 멈추는 경우가 있다. 일반적으로 파드가 클러스터 내에서 실행되지 않고 <strong>보류(pending)</strong> 중인 상태가 되는 경우이다.
  </li>
  <li>
    문제가 발생하면 일반적으로 <strong>로그</strong>를 먼저 확인하는 것이 좋다.
  </li>
</ul>

```bash
# 1. 파드의 이름을 조회
bubectl --namespace airflow get pods
```

```bash
# 2. 조회한 이름을 통해 파드 상태에 대한 자세한 내용을 조회.
kubectl --namespace describe pod [NAME-OF-POD]
```

<br>

<h2>5-5. 도커 기반 워크플로와 차이점</h2>
<ul>
  <li>
    쿠버네티스 환경에서는 태스크 컨테이너가 Airflow 워커 노드에서 실행되지 않고 <strong>쿠버네티스 클러스터 내에 별도의 노드</strong>에서 실행된다.
  </li>
    <ul>
      <li>
        쿠버네티스의 기능을 사용하여 적절한 리소스가 있는 노드에 태스크가 배포되었는지 확인할 수 있다.
      </li>
    </ul>
  <li>
    어떤 스토리지도 더 이상 Airflow 워커가 접근하지 않지만 <strong>파드</strong>에서는 스토리지에 <strong>적절한 액세스 권한</strong>을 갖고 있어야 한다.
  </li>
</ul>