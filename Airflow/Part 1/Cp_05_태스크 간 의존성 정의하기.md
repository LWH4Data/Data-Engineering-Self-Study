<ul>
  <li>
    Airflow DAG에서 <strong>태스크 의존성</strong>을 정의하는 방법을 확인한다.
  </li>
  <li>
    <strong>트리거 규칙</strong>을 사용하여 <strong>조인을 구현</strong>하는 방법을 설명한다.
  </li>
  <li>
    트리거 규칙이 작업 실행에 주는 영향에 대한 기본 지식을 제공한다.
  </li>
  <li>
    <strong>XCom</strong>을 이용하여 태스크 사이의 <strong>상태 공유 방법</strong>을 설명한다.
  </li>
  <li>
    Airflow 2의 Taskflow API를 사용해 파이썬을 많이 사용하는 <strong>DAG를 단순화</strong>하는 방법을 설명한다.
  </li>
</ul>

<br>

<h1>1. 기본 의존성 유형</h1>
<ul>
  <li>
    <strong>선형 체인(linear chain) 유형</strong>: <strong>연속적으로 실행</strong>되는 작업
  </li>
  <li>
    <strong>팬아웃/팬인(fan-out/fan-in) 유형</strong>: <strong>하나의 태스크가 여러 다운스트림</strong> 태스크에 연결되거나 <strong>다수의 태스크가 하나의 다운스트림</strong> 태스크로 연결되는 경우의 유형
  </li>
</ul>

<br>

<h2>1-1. 선형 의존성 유형</h2>
<ul>
  <li>
    <strong>태스크의 의존성</strong>을 통해 Airflow는 <strong>업스트림 의존성이 성공적으로 실행</strong>된 후에 지정된 <strong>다음 태스크 실행</strong>을 시작할 수 있다.
  </li>
  <li>
    태스크의 의존성이 명확한 경우 여러 태스크에서 <strong>순서가 명확</strong>하게 정의된다는 장점이 있다.
  </li>
</ul>

<br>

<h2>1-2. 팬인/팬아웃(Fan-in/Fan-out) 의존성</h2>
<ul>
  <li>
    <strong>팬인(Fan-in)</strong>: <strong>여러 업스트림 태스크</strong>가 <strong>하나의 다운스트림 태스크</strong>로 연결되는 경우.
  </li>
  <li>
    <strong>팬아웃(Fan-out)</strong>: <strong>하나의 업스트림 태스크</strong>가 <strong>여러 개의 다운스트림 태스크</strong>로 연결되는 경우.
  </li>
  <li>
    Fan-in/Fan-out이 섞인 DAG는 한 줄로 구성할 수 없으며 하단의 예시처럼 DAG가 구성된다.
  </li>
</ul>

```python
# 1. Fan-in/Fan-out이 섞인 DAG 구현

# fan-out: start 이후 두 개의 다운스트림 태스크로 연결
start >> [fetch_sales, fetch_weather]

# 각 fetch_sales와 fetch_weather의 내부 의존 수행.
fetch_sales >> clean_sales
fetch_weather >> clean_weather

# 두 갈래의 내부 의존 수행 후 다시 하나의 다운스트릠 태스크로 연결
[clean_sales, clean_weather] >> join_datasets

# 이후 직렬 의존 수행.
join_datasets >> tarin_model >> deploy_model
```

<br><br>

<h1>2. 브랜치하기</h1>
<ul>
  <li>
    <strong>브랜치</strong>란 <strong>조건</strong>에 따라 <strong>여러 경로 중 하나(또는 일부) 태스크만 실행</strong>하도록 분기하는 것을 의미한다.
  </li>
</ul>

<br>

<h2>2-1. 태스크 내에서 브랜치하기</h2>
<ul>
  <li>
    함수 내의 <strong>조건분기</strong>를 통해 날짜를 기준으로 하나의 태스크 내에서 두 개의 경우로 브랜치. (두 개의 태스크로 나뉘지는 않기에 명확히 브랜치라 하기에는 힘들다).
  </li>
  <li>
    <strong>DAG를 수정할 필요가 없다</strong>는 장점을 갖는다.
  </li>
  <li>
    그러나 브랜치가 하나의 태스크 내에서 이루어지기에 <strong>현재 어떤 작업을 수행</strong>하는지 추적이 어렵다는 단점이 있다.
  </li>
    <ul>
      <li>
        이를 추적하기 위해서는 태스크에 <strong>좀 더 세밀한 로깅</strong>을 포함해야한다.
      </li>
    </ul>
  <li>
    모든 조건 분기를 PythonOperator 안에서 코드로 처리하기보다는, 분리 가능한 작업은 <strong>적절한 Operator로 나누어 별도 태스크</strong>로 만들면 DAG 관리가 더 편해진다.
  </li>
</ul>

```python
# 1. 브랜치를 하지 않고 하나의 태스크를 날짜를 기반으로 분기
def _clean_sales(**context):
    # execution_date(스케줄 기준 실행일)를 가져옴
    # ERP 변경 이전 데이터는 기존 정제 로직 실행
    if context["execution_date"] < ERP_CHANGE_DATE:
        _clean_sales_old(**context)
    # ERP 변경 이후 데이터는 새로운 정제 로직 실행
    else:
        _clean_sales_new(**context)

...

# PythonOperator로 태스크 정의
clean_sales_data=PythonOperator(
    task_id="clean_sales",
    python_callable=_clean_sales,
)

# 하나의 함수 내에 두 개의 로직을 두기에 DAG를 수정할 필요는 없다.
```

<br>

<h2>2-2. DAG 내부에서 브랜치하기</h2>
<ul>
  <li>
    두 개의 개별 태스크 세트를 개발한 뒤 <strong>DAG가 적절히 선택</strong>하도록 할 수 있다.
  </li>
  <li>
    DAG의 선택 기준은 <strong>BranchPythonOperator</strong>를 통해 결정한다. 
  </li>
    <ul>
      <li>
        BranchPythonOperator에는 어떤 태스크를 수행해야하는지 결정하는 로직이 들어가며 결과로 <strong>태스크 ID를 반환</strong>한다. (브랜치 함수).
      </li>
      <li>
        즉, BranchPythonOperator의 python_callable에 <strong>브랜치 함수</strong>가 전달된다.
      </li>
    </ul>
  <li>
    단, BranchPythonOperator 중 선택되지 않은 <strong>skipped</strong>으로 처리되며 트리거 규칙이 <strong>all_success</strong>인 경우 다운스트림 태스크가 수행되지 않는다.
  </li>
    <ul>
      <li>
        이 경우 <strong>하나의 업스트림 태스크가 skip</strong> 되더라도 수행이 진행되도록 <strong>트리거 규칙을 수정</strong>해야 한다.
      </li>
      <li>
        일반적으로 <strong>none_failed</strong>를 사용하며 실패한 업스트림 태스크가 없다면 수행되도록 한다.
      </li>
    </ul>
  <li>
    단, 종종 <strong>세 개 이상의 태스크</strong>가 Fan-in 되는 경우 DAG의 <strong>가독성</strong>이 떨어질 수 있다.
  </li>
    <ul>
      <li>
        이러한 경우에는 <strong>더미 오퍼레이터</strong>를 넣어 여러 개의 업스트림 태스크를 묶어줄 수 있다.
      </li>
    </ul>
</ul>

```python
# 1. 분기 대상이 되는 두 개의 태스크 정의
fetch_sales_old=PythonOperator (...)
clean_selas_old=PythonOperator (...)

fetch_sales_new=PythonOperator(...)
fetch_sales_new=PythonOperator(...)

fetch_sales_old >> clean_sales_old
fetch_sales_new >> clean_sales_new
```

```python
# 2. BranchPythonOperator와 오퍼레이터에 사용할 브랜치 함수

# 브랜치 함수 정의
def _pick_erp_system(**context):
    if context ["execution_date"] < ERP_CHANGE_DATE:
        return "fetch_sales_old"
    else:
        return "fetch_sales_new"

# 브랜치 오퍼레이터 정의
pick_erp_system=BranchPythonOperator(
    task_id='pick_erp_system',
    python_callable=_pick_erp_system,
)

# pic_erp_system을 통해 적절한 태스크를 수행한 뒤 fan-out
pick_erp_system >> [fetch_sales_old, fetch_sales_new]
```

```python
# 3. 더미 오퍼레이터 추가.
from airflow.operators.dummy import DummyOperator

join_branch=DummyOperator(
    task_id="join_erp_branch",
    trigger_rule="none_failed"
)
```

```python
# 4. 결과 DAG

start_task >> fetch_weather
# BranchPythonOperator 수행
start_task >> pick_erp_system

fetch_weather >> clean_weather
# 하나는 skip 됨.
pick_erp_system >> [fetch_sales_new, fetch_sales_old]

fetch_sales_new >> clean_sales_new
fetch_sales_old >> clean_sales_old

# DummyOperator로 하나의 태스크로 묶어줌.
[clean_sales_new, clean_sales_old] >> join_erp_branch

# Fan-in
[clean_weather, join_erp_branch] >> join_datasets

join_datasets >> train_model >> deploy_model
```

<br><br>

<h1>3. 조건부 태스크</h1>
<ul>
  <li>
    Airflow는 특정 조건에 따라 특정 태스크를 <strong>건너뛸 수 있는 방법</strong>도 제공한다.
  </li>
</ul>

<br>

<h2>3-1. 태스크 내에서 조건</h2>
<ul>
  <li>
    PythonOperator를 사용해서 조건을 주는 방법도 있으나 로직히 혼용되고, 다른 Operator를 사용할 수 없어지기에 좋은 방법이 아니다.
  </li>
</ul>

<br>

<h2>3-2. 조건부 태스크 만들기</h2>
<ul>
  <li>
    <strong>조건부 태스크</strong>를 생성하고 조건이 실패할 경우 모든 다운스트림 작업을 건너뛰게 할 수 있다.
  </li>
    <ul>
      <li>
        혹은 조건에 해당하는 경우 태스크를 실행하도록 설계할 수도 있다.
      </li>
    </ul>
</ul>

```python
# 1. 조건부 태스크 생성하기
from airflow.exception import AirflowSkipException

# 조건 함수: "현재 실행이 최신 실행인지" 판별
def _latest_only(**context):
    # 현재 실행 윈도우 범위 계산
    left_window=context["dag"].following_schedule(context["execution_date"])
    right_window=context["dag"].following_schedule(left_window)

    # 현재 시각(UTC) 기준으로 최신 여부 판정
    #   - 최신 실행이 아니면 스킵 처리
    now=pendulum.now("UTC")
    if not left_window < now <= right_window:
        raise AirflowSkipException("Not the most recent run!")

# 조건부 태스크를 PythonOperator로 등록
latest_only=PythonOperator(
    task_id="latest_only",
    python_callable=_latest_only
)

# 조건 태스크가 성공했을 때만 deploy_model 실행
#   - 조건에 맞지 않을 경우 latest_only와 downstream은 skipped
latest_only >> deploy_model
```

<br>

<h2>3-3. 내장 오퍼레이터 사용하기</h2>
<ul>
  <li>
    <strong>가장 최근 실행한 DAG</strong>만 실행하는 것은 Airflow의 내장 클래스인 <strong>LastOnlyOperator 클래스</strong>를 사용할 수 있다.
  </li>
</ul>

```python
# 1. LastOnlyOperator를 통해 가장 최근 실행한 DAG 수행.
from airflow.operator.lastest_only import LatestOnlyOperator

lastest_only=LastestOnlyOperator(
    task_id="lastest_only",
    dag=dag
)

join_datasets >> train_model >> deploy_model
lastest_only >> deploy_model
```

<br><br>

<h1>4. 트리거 규칙에 대한 추가 정보</h1>
<ul>
  <li>
    <strong>태스크가 실행되는 시기</strong>를 정확히 결정하는 것은 Airflow의 <strong>트리거 규칙</strong>에 의해 제어된다.
  </li>
  <li>
    Airflow는 DAG를 실행할 때 <strong>각 태스크를 지속적으로 확인</strong>하여 실행 여부를 확인하며 태스크 실행이 가능하다면 스케줄러가 해당 태스크를 <strong>실행 예약</strong>한다.
  </li>
    <ul>
      <li>
        트리거는 실행 예약된 태스크가 <strong>실행될 시점</strong>을 결정한다.
      </li>
    </ul>
</ul>

<br>

<h2>4-1. 트리거 규칙이란?</h2>
<ul>
  <li>
    트리거 규칙은 기본적으로 <strong>all_success</strong>이다.
  </li>
  <li>
    트리거 규칙을 사용하지 않은 Umbrella DAG를 테스트하면 의존성이 완료된 태스크들이 실행 예약되는 것을 확인할 수 있다.
  </li>
</ul>

<br>

<h2>4-2. 실패의 영향</h2>
<ul>
  <li>
    태스크가 실패(failed)하거나 건어뛰어진다면(skipped) 다운스트림으로 <strong>전파(propagation)</strong>되며 <strong>트리거 규칙</strong>을 기반으로 다음 수행이 결정된다.
  </li>
</ul>

<br>

<h2>4-3. 기타 트리거 규칙, p105</h2>
<ul>
  <li>
    <strong>all_done</strong>: 결과에 상관없이 업스트림의 수행이 완료되면 수행한다.
  </li>
  <li>
    <strong>one_success/one_fail</strong>: 모든 업스트림 태스크의 완료를 기다리지 않고 하나의 업스트림 태스크의 성공/실패 조건만을 필요로 한다.
  </li>
  <li>
    이외에도 여러 트리거가 장표로 정리되어 있다.
  </li>
</ul>

<br><br>

<h1>5. 태스크 간 데이터 공유</h1>
<ul>
  <li>
    <strong>XCom</strong>을 사용하여 태스크 간 <strong>작은 데이터(최대 10MB 정도)</strong>를 공유할 수 있다.
  </li>
</ul>

<br>

<h2>5-1. XCom을 사용하여 데이터 공유하기</h2>
<ul>
  <li>
    Umbrella DAG를 사용하여 실습. 머신러닝 모델의 버전 식별자를 XCom으로 관리한다.
  </li>
  <li>
    BashOperator와 PythonOperator 등 일부 오퍼레이터는 XCom 값을 자동으로 게시하는 기능을 제공한다.
  </li>
</ul>

```python
# 1. xcom_push를 사용해 명시적으로 XCom 값을 게시
def _train_model(**context):
    model_id=str(uuid.uuid4())
    # push된 값은 Airflow 메타데이터 DB(e.g. Postgres, MySQL, SQLite 등)에 저장된다.
    context["task_instance"].xcom_push(key="model_id", value=model_id)

train_model=PythonOperator(
    task_id="train_model",
    python_callable=_train_model
)
```

```python
# 2. xcom_pull을 통해 XCom을 확인.
def _deploy_model(**context):
    # 현재 DAG 실행(run_id) 안에서 XCom을 조회한다.
    #   - 필요시 dag_id와 execution_date를 지정할 수도 있다.
    #   - 여기서는 task_id="train_model", key="model_id"로 검색
    #   - 따라서 train_model 태스크에서 push한 값과 동일한 값을 가져온다.
    model_id=context["task_instance"].xcom_pull(
        task_ids="train_model", key="model_id"
    )
    print(f"Deploying model {model_id}")

deploy_model=PythonOperator(
    task_id="deploy_model",
    python_callable=_deploy_model
)
```

```python
# 3. 템플릿에서 XCom 값 사용하기.
def _deploy_model(templates_dict, **context):
    model_id=templates_dict["model_id"]
    print(f"Deploying model {model_id}")

deploy_model=PythonOperator(
    task_id="deploy_model",
    python_callable=_deploy_model,
    templates_dict={
        "model_id": "{{task_instance.xcom_pull( \
        task_ids='train_model', key='model_id')}}"
    },
)
```

<br>

<h2>5-2. XCom 사용 시 고려사항</h2>
<ul>
  <li>
    일부 태스크는 <strong>묵시적인 의존성(implicit dependency)</strong>이 필요한 문제가 있다.
  </li>
    <ul>
      <li>
        묵시적 의존성은 <strong>DAG</strong>에 표시되지 않으며 <strong>태스크 스케줄</strong> 시에 고려되지 않는다. 따라서 XCom 값을 공유할 때에 훨씬 복잡하다.
      </li>
    </ul>
  <li>
    XCom이 오퍼레이터의 <strong>원자성</strong>을 무너뜨리는 패턴이 될 수 있다.
  </li>
    <ul>
      <li>
        예를 들어 API 접근 토큰을 가져와 전달하는 경우 하나의 DAG에서 API 접근 토큰이 달라질 수 있다.
      </li>
    </ul>
  <li>
    XCom이 저장하는 모든 값은 <strong>직렬화(serialization)</strong>를 지원해야 한다.
  </li>
    <ul>
      <li>
        람다 또는 여러 다중 멀티프로세스 관련 클래스의 파이썬 유형은 XCom을 저장할 수 없다.
      </li>
      <li>
        사용중인 백엔드에 의해 XCom 값의 저장 크기가 제한될 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>5-3. 커스텀 XCom 백엔드 사용하기</h2>
<ul>
  <li>
    컴스텀 XCom 백엔드를 지정할 수 있는 옵션이 존재한다.
  </li>
    <ul>
      <li>
        BaseXCom 기본 클래스가 상속되어야 한다.
      </li>
      <li>
        값을 직렬화 및 역직렬화(deserialization)하기 위해 두 가지 정적 메서드를 구현해야 한다.
      </li>
    </ul>
  <li>
    커스텀 백엔드 클래스에서 직렬화 메서든느 XCom 값이 오퍼레이터 내에 게시될 때마다 호출된다.
  </li>
  <li>
    역직렬화 메서드는 XCom 값이 백엔드에서 가져올 때 호출된다.
  </li>
  <li>
    원하는 백엔드 클래스가 있다면 Airflow 구성에서 xcom_bachend 매개변수를 사용해 클래스를 사용하도록 Airflow를 구성할 수 있다.
  </li>
  <li>
    커스텀 XCom 백엔드는 XCom 값 저장 선택을 다양하게 가능하도록 한다.
  </li>
</ul>

```python
# 1. 커스텀 XCom 백엔드 구조.
from typing import Any
from airflow.models.xcom import BaseXCom

class CustomXComBackend(BaseXCom):
    @staticmethod
    def serialize_value(value: Any):
        ...
    @staticmethod
    def deserialize_value(result) -> Any:
        ...
```

<br><br>

<h1>6. Taskflow API로 파이썬 태스크 연결하기</h1>
<ul>
  <li>
    Taskflow API를 사용하여 PythonOperators를 사용하고 XCom으로 데이터를 전달하는 경우 코드를 단순화 할 수 있다.
  </li>
</ul>

<br>

<h2>6-1. Taskflow API로 파이썬 태스크 단순화하기</h2>

```python
# 1. Taskflow API를 사용하지 않고 구성
def _train_model(**context):
    model_id=str(uuid.uuid4())
    context["task_instance"].xcom_push(key="model_id", value=model_id)

def _deploy_model(**context):
    model_id=context["task_instance"].xcom_pull(
        task_ids="train_model", key="model_id"
    )
    print(f"Deploying model {model_id}")

with DAG(...) as dag:
    ...
    train_model=PythonOperator(
        tesk_id="train_model",
        python_callable=_train_model
    )

    deploy_model=PythonOperator(
        task_id="deploy_model",
        python_callable=_deploy_model
    )

    ...
    join_datasets >> train_model >> deploy_model
```

```python
# 2. Taskflow API를 사용하여 코드 구성
from airflow import DAG
from airflow.decorators import task
import uuid
import pendulum

with DAG(
    dag_id="ml_pipeline",
    start_date=pendulum.today("UTC").add(days=-1),
    schedule_interval="@daily",
    catchup=False,
) as dag:

    # 1. 모델 학습 태스크
    @task
    def train_model() -> str:
        model_id = str(uuid.uuid4())
        print(f"Trained model {model_id}")
        return model_id   # 반환값이 자동으로 XCom에 저장됨

    # 2. 모델 배포 태스크
    @task
    def deploy_model(model_id: str):
        print(f"Deploying model {model_id}")

    # 3. DAG 의존성 (TaskFlow API 방식은 함수 호출로 연결)
    model_id = train_model()
    deploy_model(model_id)
```

<br>

<h2>6-2. Taskflow API를 사용하지 않는 경우</h2>
<ul>
  <li>
    Taskflow API는 파이썬 태스크와 태스크 간 의존성을 좀 더 간단하게 구현할 수 있도록 한다.
  </li>
  <li>
    Taskflow API를 활용하면 태스크 간 의존성을 확인할 수 있다.
  </li>
  <li>
    PythonOperator를 사용하여 구현되는 파이썬 스크립트에 국한된다.
  </li>
    <ul>
      <li>
        다른 오퍼레이터들과 혼용은 문제가 없지만 의존성을 관리하는 것이 어렵다.
      </li>
    </ul>
</ul>

```python
# 1. 다른 오퍼레이터들과 Taskflow를 결합하여 사용.
with DAG(...) as dag:
    # 더미 시작 태스크
    start=DummyOperator(task_id="start")
    ...

    # Fan-in: clean_sales, clean_weather가 끝나야 join_datasets 실행
    [clean_sales, clean_weather] >> join_datasets

    # TaskFlow API 태스크 (학습)
    #   - 반환값은 자동으로 XCom에 저장됨
    @task
    def train_model():
        model_id=str(uuid.uuid4())
        return model_id

    # TaskFlow API 태스크 (배포)
    #   - train_model의 반환값(XCom)을 함수 인자로 자동 주입받음
    @task
    def deploy_model(model_id: str):
        print(f"Deploying model {model_id}")
    
    # DAG 의존성 (TaskFlow API 방식)
    #   - train_model이 실행되고 → 반환된 model_id가 XCom에 저장됨
    #   - deploy_model은 그 값을 받아 실행됨
    model_id=train_model()
    deploy_model(model_id)

    # 전통 오퍼레이터(join_datasets)와 TaskFlow 태스크 연결
    #   - join_datasets 완료 후 train_model 실행
    join_datasets >> model_id
```