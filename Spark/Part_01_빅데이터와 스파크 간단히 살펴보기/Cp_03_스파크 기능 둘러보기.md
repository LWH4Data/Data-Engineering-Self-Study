<ul>
  <li>
    spark-submit 명령으로 운영용 애플리케이션 실행
  </li>
  <li>
    Dataset: 타입 안정성(type-safe)을 제공하는 구조적 API
  </li>
  <li>
    구조적 스트리밍
  </li>
  <li>
    머신러닝과 고급 분석
  </li>
  <li>
    RDD: 스파크의 저수준 API
  </li>
  <li>
    SparkR
  </li>
  <li>
    서드파티 패키지 에코시스템
  </li>
</ul>

<br>

<h1>1. 운영용 애플리케이션 실행하기</h1>
<ul>
  <li>
    <strong>spark-submit</strong> 명령을 사용하면 대화형 shell에서 개발한 프로그램을 <strong>운영용 애플리케이션으로 전환</strong>할 수 있다.
  </li>
  <li>
    spark-submit 명령은 애플리케이션 코드를 <strong>클러스터에 전송</strong>하여 <strong>실행</strong>하는 역할을 한다.
  </li>
  <li>
    클러스터에 전송된 애플리케이션은 <strong>작업이 종료</strong>되거나 <strong>에러가 발생</strong>할 때까지 실행된다.
  </li>
  <li>
    spark application은 Stand Alone, Mesos, YARN 클러스터 매니저를 이용해 실행된다.
  </li>
</ul>

```bash
# 1. pyspark를 사용하지 않고 spark 컨테이너 접속
docker run --rm -it \
  # 컨테이너에 접속했을 때 디렉터리
  -w /opt/spark \
  apache/spark:3.5.2 bash
```

```bash
# 2. ./bin/spark-submit의 spark-submit을 통해 애플리케이션을 실행한다.
# (현재 버전에 맞게 코드 수정).

# jar 파일
./bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local ./examples/jars/spark-examples_2.12-3.5.2.jar 10

# python
# ./bin/spark-submit을 통해 파이썬 스크랩트 실행
./bin/spark-submit \
--master local \
./example/src/main/python/pi.py 10
```

<br><br>

<h1>2. Dataset: 타입 안정성을 제공하는 구조적 API</h1>

- 