```bash
MSYS_NO_PATHCONV=1 MSYS2_ARG_CONV_EXCL="*" \
docker run -it --rm \
  -p 4040:4040 \
  -v /c/Users/SSAFY/Desktop/spark-prac/Spark-The-Definitive-Guide:/workspace/Spark-The-Definitive-Guide \
  apache/spark:3.5.2 \
  /opt/spark/bin/pyspark
```

<h1>1. 내고장성과 체크포인팅</h1>
<ul>
  <li>
    구조적 스티리밍 앱은 단순한 재시작만으로 여러 장애 상황을 극복한다. 이를 위해서는 Spark 엔진이 자동으로 관리하는 <strong>체크포인트</strong>와 <strong>WAL</strong>을 사용하도록 해야한다.
  </li>
    <ul>
      <li>
        구체적으로는 체크포인팅과 WAL 정보를 저장하는 <strong>신뢰도 높은 파일 시스템</strong>(e.g. HDFS, S# 또는 기타 호환 가능 파일 시스템)의 <strong>체크포인트 경로를 쿼리에 설정</strong>해야 한다.
      </li>
    </ul>
  <li>
    구조적 스트리밍은 설정에 따라 관련된 </strong>모든 진행 상황 정보와 중간 상탯값</strong>을 <strong>체크 포인트 경로에 저장</strong>한다.<br>→ 장애 상황이 발생하면 <strong>앱을 다시 시작</strong>하여 <strong>중간 상탯값을 저장한 체크 포인트 경로를 참조</strong>하도록 한다.<br>→ 자동적으로 앱이 관리된다.
  </li>
  <li>
    체크포인트 디렉터리나 디렉터리의 <strong>파일이 제거</strong>된 경우 장애 상황에서 앱을 정상적으로 <strong>복구할 수 없으며 스트림 처리를 처음부터 다시 시작</strong>해야 한다.
  </li>
</ul>

```python
# 1. 체크포인트를 사용하기 위해 writeStream의 checkpointLocation 옵션에 체크포인트 경로
#    를 지정한다.
#    (체크포인트는 장애 복구 및 상태 저장에 사용됨)

# 정적 데이터 초기화 (스키마 추출용)
static = spark.read.json("/workspace/Spark-The-Definitive-Guide/data/activity-data")

# Streaming DataFrame 생성
streaming = spark\
    .readStream\
    .schema(static.schema)\
    .option("maxFilesPerTrigger", 10)\
    .json("/workspace/Spark-The-Definitive-Guide/data/activity-data")\
    .groupBy("gt")\
    .count()

# 스트리밍 쿼리 실행 (메모리 싱크 + 체크포인트 설정)
query = streaming\
    .writeStream\
    .outputMode("complete")\
    .option("checkpointLocation", "some/python/location/")\
    .queryName("test_python_stream")\
    .format("memory")\
    .start()

# 메모리 테이블에서 현재까지의 결과 조회
spark.sql("SELECT * FROM test_python_stream").show()
```

<br><br>

<h1>2. 애플리케이션 변경하기</h1>
<ul>
  <li>
    스트리밍 앱을 업데이트할 때 <strong>이전 체크포인트 데이터</strong>를 고려해야 한다. 즉, 앱을 업데이트한다면 업데이트 내용에 <strong>중대한 변화가 있는지 확인</strong>한다.
  </li>
</ul>

<br>

<h2>2-1. 스트리밍 애플리케이션 코드 업데이트하기</h2>
<ul>
  <li>
    구조적 스트리밍 앱을 다시 시작하기 전에 <strong>특정 유형의 앱 코드</strong>를 변경할 수 있으며 사용자 정의 함수는 <strong>시그니처</strong>가 같은 경우에만 코드 수정이 가능하다.
  </li>
    <ul>
      <li>
        <strong>시그니처</strong>: 함수나 메서드를 구별하는 외형 (형태).
      </li>
    </ul>
  <li>
    <strong>버그를 수정</strong>해야하는 상황에서 유용하게 사용할 수 있다.
  </li>
    <ul>
      <li>
        새로운 유형의 데이터가 유입되어 데이터 파싱 함수를 변경해야하는 경우 <strong>새로운 버전의 파싱 함수</strong>를 만들어 <strong>다시 컴파일</strong>하면 된다.
      </li>
      <li>
        다시 시작할 시에 <strong>장애가 발생한 스트림 지점</strong>부터 다시 처리할 수 있다.
      </li>
    </ul>
  <li>
    중대한 변화가 아니라면 새로운 체크포인트 디렉터리를 사용할 필요가 없지만 중대한 변화가 일어나는 경우 <strong>새로운 체크포인트 디렉터리</strong>를 사용해야 한다.
  </li>
    <ul>
      <li>
        새로운 처리에 필요한 정보를 만들어내지 못하는 등 큰 변화가 필요하다면 새로운 체크포인트 디렉터리부터 다시 시작해야한다.
      </li>
    </ul>
</ul>

<br>

<h2>2-2. 스파크 버전 업데이트하기</h2>
<ul>
  <li>
    주조적 스트리밍 앱은 <strong>이전 체크포인트 디렉터리</strong>를 사용해 재시작할 수 있다.
  </li>
  <li>
    체크포인트 포맷은 <strong>상위 버전과 호환</strong>되도록 설계되어 있다.
  </li>
    <ul>
      <li>
        새로운 Spark 버전이 이전 체크포인트 정보를 사용하지 못하면 <strong>릴리스 노트</strong>에 명시된다. 단, 버전을 업데이트 한다면 호환성을 확인해 보는 것이 좋다.
      </li>
    </ul>
</ul>

<br>

<h2>2-3. 애플리케이션의 초기 규모 산정과 재조정하기</h2>
<ul>
  <li>
    클러스터는 평균 데이터 발생량 이상으로 <strong>데이터가 급증</strong>하는 상황에서도 <strong>안정적으로 처리</strong>할 수 있는 크기를 제공해야 한다.
  </li>
  <li>
    <strong>유입율이 처리율보다 훨씬 크다면</strong> 클러스터나 <strong>앱의 크기</strong>를 늘려야 한다.
  </li>
  <li>
    <strong>익스큐터의 수</strong>를 조정하여 앱의 크기를 조정할 수도 있다.
  </li>
  <li>
    자원 관리를 고려한 클러스터 환경을 구축할 때에는 <strong>비즈니스 로직</strong>과 <strong>인프라 구조</strong>를 고려해야 한다.
  </li>
</ul>

<br><br>

<h1>3. 메트릭과 모니터링</h1>
<ul>
  <li>
    Spark에서는 <strong>스트리밍 쿼리의 상태</strong>와 <strong>최근에 실행된 진행 상황</strong>을 조회할 수 있는 <strong>두 가지 API</strong>를 제공한다.
  </li>
</ul>

<br>

<h2>3-1. 쿼리 상태</h2>
<ul>
  <li>
    <strong>query.status</strong>를 사용해 지금 스트림에서 <strong>어떤 처리</strong>를 하고 있는지 알 수 있다. 
  </li>
  <li>
    정보는 startStream 메서드에서 반환한 쿼리 객체의 <strong>status 속성</strong>으로 확인하 수 있다.
  </li>
  <li>
    특정 쿼리의 상태를 얻기 위해서는 현재 상태를 반환하는 <strong>query.status 명령</strong>을 실행해야 한다. 결과는 해당 시점에 스트림에서 일어나고 있는 <strong>상황의 상세 정보</strong>를 제공한다.
  </li>
  <li>
    <strong>Standalone</strong>의 경우 프로세스에서 임의 코드를 실행할 수 있는 shell이 없기에 특정 포트로 요청이 들어오면 query.status 호출 결과를 반환받는 <strong>가벼운 HTTP 서버 기반의 모니터링 시스템</strong>을 구축해 상태를 확인한다.
  </li>
    <ul>
      <li>
        혹은 <strong>StreamingQueryListener API</strong>를 사용해 더 많은 이벤트를 수신할 수 있다.
      </li>
    </ul>
</ul>

```python
# 1. 특정 쿼리의 상태를 얻기
query.status
```

<br>

<h2>3-2. 최근 진행 상황</h2>
<ul>
  <li>
    <strong>쿼리 진행 상황</strong>은 <strong>진행 상황 API(progress API)</strong>를 이용해 확인할 수 있다.
  </li>
  <li>
    <strong>query.recentProgress 명령</strong>으로 처리율과 배치 주기 등 <strong>시간 기반의 정보</strong>를 확인할 수 있다.
  </li>
  <li>
    스트리밍 쿼리의 진행 상황은 스트림을 사용하는 <strong>입력 소스</strong>와 <strong>출력 싱크</strong>의 정도보 함께 제공한다.
  </li>
  <li>
    출력 결과는 <strong>스트림의 상태</strong>와 관련된 상세 정보가 포함되어 있으며 <strong>특정 시점의 스냅샷</strong>임을 기억해야한다.
  </li>
  <li>
    스트림의 상태를 <strong>연속적</strong>으로 얻으려면 이 <strong>API를 반복적으로 요청</strong>해야 한다.
  </li>
  <li>
    출력된 필드 대부분은 이름만으로도 의미를 알 수 있다.
  </li>
</ul>

```python
# 1. 최근 진행 상황 확인
query.recentProgress
```

<h3>3-2-1. 유입율과 처리율</h3>
<ul>
  <li>
    <strong>유입율(input rate)</strong>은 입력 소스에서 구조적 스트리밍 내부로 데이터가 <strong>유입되는 양</strong>을 나타낸다.
  </li>
  <li>
    <strong>처리율</strong>은 유입된 데이터를 <strong>처리하는 속도</strong>를 나타낸다.
  </li>
  <li>
    이상적인 상황은 유입률과 처리율이 서로 달라야 하며 유입률이 처리율보다 큰 상황은 피해야한다.
  </li>
</ul>

<h3>3-2-2. 배치 주기</h3>
<ul>
  <li>
    구조적 스트리밍은 <strong>배치 처리</strong>와 처리량을 줄이는 대신 <strong>느리게 응답하는 기능</strong> 모두 제공한다.
  </li>
  <li>
    구조적 스트리밍은 데이터를 연산할 때 다양한 이벤트를 처리하며 이에 따라 <strong>배치 주기</strong>가 변한다.
  </li>
</ul>

<br>

<h2>3-3 스파크 UI</h2>
<ul>
  <li>
    각각의 스트리밍 앱은 Spark UI에서 <strong>트리거마다 생성된 짧은 Job</strong>이 <strong>누적된 형태</strong>로 나타난다.
  </li>
  <li>
    Spark UI는 앱의 메트릭, 쿼리 실행 계획, 태스크 주기 그리고 로그 정보도 제공한다.
  </li>
  <li>
    구조적 스트리밍은 DStream API와 다르게 Streaming 탭을 사용하지 않는다.
  </li>
</ul>

<br><br>

<h1>4. 알림</h1>
<ul>
  <li>
    <strong>Job이 실패</strong>하거나 <strong>유입률보다 처리율이 떨어지는 경우</strong> 자동으로 <strong>알려주는 기능</strong>이 필요하다. 이를 위해 Spark에서는 알림 시스템(alert system)을 제공한다.
  </li>
  <li>
    일반적으로는 <strong>최근 진행 상황 API</strong>를 기반으로 구축한다.
  </li>
  <li>
    쿼리 모니터링과 알림 외에도 <strong>클러스터와 전체 앱의 상태</strong>를 모니터링하고 알림을 발생시켜야 한다.
  </li>
</ul>

<br><br>

<h1>5. 스트리밍 리스너를 사용한 고급 모니터링</h1>
<ul>
  <li>
    <strong>StreamingQueryListener 클래스</strong>를 이용해 <strong>비동기 방식</strong>으로 <strong>스트리밍 쿼리 정보를 수신</strong>한 후 <strong>다른 시스템에 자동으로 해당 정보를 전송</strong>하여 모니터링 및 알림 시스템을 구현할 수 있다.
  </li>
</ul>

```scala
// 1. StreamingQueryListener 클래스를 이용한 모니터링 설정.
val spark: SparkSession = ...

// StreamingQueryListener를 등록해서 스트리밍 쿼리의 상태 변화를 모니터링
spark.streams.addListener(new StreamingQueryListener)() {

  // 쿼리가 시작될 때 호출되는 콜백
  override def onQueryStarted(queryStarted: QueryStartedEvent): Unit = {
    println("Query started: " + queryStarted.id)
  }

  // 쿼리가 종료될 때 호출되는 콜백
  override def onQueryTerminated(queryTerminated: QueryTerminatedEvent): Unit = {
    println("Query terminated: " + queryTerminated.id) 
  }

  // 쿼리가 실행 중에 진행 상황(배치 단위)을 보고할 때 호출되는 콜백
  override def onQueryProgress(queryProgrss: QueryProgressEvent): Unit = {
    println("Query made progress: " + queryProgress.progress)
  }
})
```

```scala
// 2. kafka로 송출하는 클래스 정의
class KafkaMetrics(servers: String) extends StreamingQueryListener {
  val kafkaProperties = new Properties()
  kafkaProperties.put(
    "bootstrap.servers",
    servers)
  kafkaProperties.put(
    "key.serializer",
    "kafkashaded.org.apache.kafka.common.serialization.StringSerializer")

  val producer = new KafkaProducer[String, String](kafkaProperties)

  import org.apache.spark.sql.streaming.StreamingQueryListener
  import org.apache.kafka.clients.producer.KafkaProducer

  override def onQueryProgress(event:
    StreamingQueryListener.QueryProgressEvent): Unit = {
    producer.send(new ProducerRecord("streaming-metrics",
      event.progress.json))
    }
    override def onQueryStarted(event:
      StreamingQueryListener.QueryStartedEvent): Unit = {}
    override def onQueryTerminated(event:
      StreamingQueryListener.QueryTerminatedEvent): Unit = {}
}
```