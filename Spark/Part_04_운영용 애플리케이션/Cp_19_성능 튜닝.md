<ul>
  <li>
    네트워크와 같은 환경적 요인은 가변적이기에 <strong>코드나 설정 변경</strong>을 통한 성능 제어 방법을 알아야 한다.
  </li>
  <li>
    Spark job의 최적화의 주요 영역은 다음과 같다.
  </li>
    <ul>
      <li>
        코드 수준의 설계. (e.g. RDD와 DataFrame 중 하나를 선택)
      </li>
      <li>
        보관용 데이터
      </li>
      <li>
        조인
      </li>
      <li>
        집계
      </li>
      <li>
        데이터 전송
      </li>
      <li>
        애플리케이션별 속성
      </li>
      <li>
        익스큐터 프로세스의 JVM
      </li>
      <li>
        워커 노드
      </li>
      <li>
        클러스터와 배포 환경 속성
      </li>
    </ul>
  <li>
    Spark job의 튜닝 방법은 크게 두 가지로 정의할 수 있다. 하나는 속성값을 설정하거나 런타임 환경을 변경하는 <strong>간접적 방법</strong>이다.
  </li>
    <ul>
      <li>
        간접적 방식은 <strong>전체 Spark 앱이나 Spark job</strong>에 영향을 미친다.
      </li>
    </ul>
  <li>
    두 번째는 개별 Spark job, stage, task 성능 튜닝을 시도하거나 코드 설계를 변경해 <strong>직접적으로</strong> 성능을 높이는 방법이다.
  </li>
    <ul>
      <li>
        <strong>앱의 특정 영역</strong>에만 영향을 주기에 전체 Spark 앱이나 Spark job에는 영향을 미치지 않는다.
      </li>
    </ul>
  <li>
    Job의 성능 향상을 확인하는 데 가장 좋은 방법 중 하나는 좋은 <strong>모니터링 도구</strong>와 <strong>job 이력 추적 환경 구성</strong>이다.
  </li>
</ul>

<br>

<h1>1. 간접적인 성능 향상 기법</h1>
<h2>1-1. 설계 방안</h2>
<ul>
  <li>
    좋은 아키텍처를 갖고 시작하는 것이 중요하다.
  </li>
</ul>

<h3>1-1-1. 스칼라 vs 자바 vs 파이썬 vs R</h3>
<ul>
  <li>
    언어의 선택은 개발 환경에 따라 달라지며 정답은 없다.
  </li>
  <li>
    머신러닝을 예로 들면 Spark의 구조적 API를 통해 ETL만 수행하고 머신러닝은 R 또는 python과 같은 다른 언어로 수행하는 것이 좋다.
  </li>
  <li>
    구조적 API로 만들 수 없는 사용자 정의 transformation을 사용해야 하는 경우, 즉 RDD transformation이나 UDF를 사용하는 경우 R과 python은 사용하지 않는 것이 좋다.
  </li>
    <ul>
      <li>
        여러 언어를 넘나드는 사용자 정의 함수를 정의하면 데이터 타입과 처리 과정을 보장하기 힘들기 때문이다.
      </li>
      <li>
        만약 사용해야 한다면 python을 주 언어로 사용하고 scala로 일부를 변경하거나 UDF를 정의한다면 사용성(usability), 유지 관리성(maintainablility), 성능(performance) 간의 좋은 균형을 이룰 수 있다.
      </li>
    </ul>
</ul>

<h3>1-1-2. DataFrame vs SQL vs Dataset vs RDD</h3>
<ul>
  <li>
    모든 언어의 DataFrame, Dataset 그리고 SQL의 <strong>속도는 동일</strong>하다.
  </li>
  <li>
    성능을 개선하고 싶다면 UDF 대신 <strong>DataFrame</strong>이나 <strong>SQL</strong>을 사용해야 한다.
  </li>
  <li>
    저수준에서 RDD를 직접 사용자가 정의할 수 있으나 대부분 상황에서 사용자가 직접 RDD를 작성하는 것보다 <strong>Spark의 최적화 엔진</strong>이 더 나은 RDD 코드를 만든다.
  </li>
    <ul>
      <li>
        사용자가 직접 RDD 코드를 작성하면 Spark가 release 될 때마다 <strong>Spark SQL 엔진에 추가</strong>되는 최적화 기법을 사용할 수 없다.
      </li>
    </ul>
  <li>
    RDD를 사용하려면 scala 혹은 java를 사용해야 한다. RDD 코드는 python 프로세스를 오가는 많은 데이터를 직렬화해야하기 때문이다.
  </li>
</ul>

<br>

<h2>1-2. RDD 객체 직렬화</h2>
<ul>
  <li>
    <strong>Kryo</strong>를 이용해 직접 정의한 데이터 타입을 직렬화 할 수 있다. 
  </li>
  <li>
    Kryo는 java 직렬화보다 훨씬 간결하고 효율적이다. 단, 앱에서 사용할 <strong>클래스를 등록</strong>해야 한다.
  </li>
  <li>
    Kryo 직렬화를 사용할 경우 spark.serializer 속성값을 org.apache.spark.classesToRegister 속성값을 지정해 <strong>Kryo 시리얼라이저에 등록</strong>한다.
  </li>
</ul>

```bash
# 1. SparkConf에 클래스명을 전달.
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
```

<br>

<h2>1-3. 클러스터 설정</h2>
<ul>
  <li>
    <strong>머신 자체의 성능을 모니터링</strong>하는 것이 클러스터 설정을 최적화하는 데 가장 많은 도움이 된다.
  </li>
</ul>

<h3>1-3-1. 클러스터/애플리케이션 규모 산정과 자원 공유</h3>
<ul>
  <li>
    자원 공유와 스케줄링 문제로 요약할 수 있다. 다양한 선택지가 존재하며 16장 후반부와 17장 일부 설정을 참고.
  </li>
</ul>

<h3>1-3-2. 동적 할당</h3>
<ul>
  <li>
    Spark는 워크로드에 따라 앱이 차지할 자원을 <strong>동적으로 조절</strong>하는 메커니즘을 제공한다.
  </li>
  <li>
    해당 기능은 다수의 앱이 Spark 클러스터 <strong>자원을 공유</strong>하는 환경에서 특히 유용하다.
  </li>
  <li>
    기능은 기본적으로 비활성화 되어 있으며 spark.dynamicAllocation.enabled 속성값을 true로 설정하여 <strong>모든 클러스터 매니저</strong>에서 사용할 수 있다.
  </li>
</ul>

<br>

<h2>1-4. 스케줄링</h2>
<ul>
  <li>
    스케줄링 최적화는 연구와 실험이 필요한 영역이다. 따라서 아래 방법들을 시도해볼 수 있다.
  </li>
    <ul>
      <li>
        자원을 더 <strong>효율적으로 공유</strong>하기 위해 <strong>spark.scheduler.mode 속성값을 FAIR</strong>로 설정.
      </li>
      <li>
        앱에 필요한 익스큐터 <strong>코어 수를 조절</strong>하기 위해 <strong>--max-executor-cores 인수</strong>를 사용한다.
      </li>
      <li>
        --max-executor-cores 인수로 값을 설정해 사용자 앱이 클러스터의 <strong>자원을 모두</strong> 사용하지 못하도록 막을 수 있다.
      </li>
      <li>
        클러스터 매니저에 따라서는 spark.cores.max 값을 설정해 <strong>기본값을 변경</strong>할 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>1-5. 보관용 데이터</h2>
<h3>1-5-1. 파일 기반 장기 데이터 저장소</h3>
<ul>
  <li>
    데이터를 <strong>바이너리 형태</strong>로 저장하려면 <strong>구조적 API</strong>를 사용하는 것이 좋다.
  </li>
  <li>
    <strong>CSV</strong>와 같은 파일은 구조화되어 있는 것처럼 보이지만 <strong>파싱 속도</strong>가 아주 느리고 <strong>예외 상황</strong>이 자주 발생한다.
  </li>
  <li>
    가장 효율적으로 사용할 수 있는 파일 포맷으로는 <strong>아파치 파케이</strong>가 있다.
  </li>
    <ul>
      <li>
        파케이는 데이터를 바이너리 파일로 <strong>컬럼 지향 방식</strong>으로 저장한다. 
      </li>
      <li>
        쿼리에서 <strong>사용하지 않는 데이터</strong>를 빠르게 건너뛸 수 있도록 몇 가지 <strong>통계를 함께 저장</strong>한다.
      </li>
    </ul>
  <li>
    Spark는 파케이 데이터소스를 내장하고 있으며 파케이 파일과 잘 호환된다.
  </li>
</ul>

<h3>1-5-2. 분할 가능한 파일 포맷과 압축</h3>
<ul>
  <li>
    어떤 파일 포맷을 선택하더라도 <strong>분할 가능한 포맷</strong>인지 확인해야 한다.
  </li>
  <li>
    분할 가능한 포맷을 사용하면 태스크가 파일의 서로 다른 부분을 <strong>동시에</strong> 읽을 수 있다.
  </li>
    <ul>
      <li>
        JSON과 같이 분할이 불가한 포맷을 사용하면 <strong>단일 머신</strong>에서 전체 파일을 읽어야 하기에 병렬성이 급격히 떨어진다.
      </li>
    </ul>
  <li>
    ZIP 파일이나 TAR 압축 파일은 분할이 불가하다. Hadoop이나 Spark와 같은 병렬 처리 프레임워크는 gzip, bzip2 또는 lz4를 이용해 <strong>압출된 파일을 분할</strong>할 수 있다.
  </li>
</ul>

<h3>1-5-3. 테이블 파티셔닝</h3>
<ul>
  <li>
    테이블 파티셔닝은 데이터의 날짜 같은 <strong>key를 기준</strong>으로 <strong>개별 디렉터리 파일에 저장</strong>하는 것을 의미한다.
  </li>
  <li>
    예를 들어 자주 사용하는 컬럼을 key로 분할하면 관련 없는 데이터 파일을 건너 뛸 수 있다.
  </li>
  <li>
    파티셔닝을 <strong>너무 작은 단위</strong>로 분할하면 작은 크기의 파일이 대량으로 생겨 저장소 시스템에서 전체 파일의 목록을 읽을 때 오버헤드가 발생한다.
  </li>
</ul>


<h3>1-5-4. 버켓팅</h3>
<ul>
  <li>
    데이터를 버켓팅하면 사용자가 조인이나 집계를 수행하는 방식에 따라 데이터를 <strong>사전 분할(pre-partition)</strong>할 수 있다.
  </li>
  <li>
    버켓팅을 통해 전체 파티션에 <strong>균등하게 데이터를 분산</strong>하여 성능과 안정성이 향상된다.
  </li>
  <li>
    버켓팅은 <strong>물리적</strong> 데이터 분할 방법의 보완재로 보통 <strong>파티셔닝과 함께 적용</strong>한다.
  </li>
</ul>

<h3>1-5-5. 파일 수</h3>
<ul>
  <li>
    데이터를 파티션이나 버켓으로 구성하는 경우 저장하는 <strong>파일의 크기</strong>도 고려해야 한다.
  </li>
  <li>
    작은 파일이 많은 경우 파일 목록 조회와 파일 읽기 과정에서 부하가 발생한다.
  </li>
  <li>
    파일 크기에 정답은 없지만 어떤 방식을 선택하던 <strong>trade-off를 감안</strong>해야한다.
  </li>
    <ul>
      <li>
        파일의 수가 많은 경우 스케줄러는 많은 수의 파일을 찾아 읽어야하기에 네트워크와 잡 스케줄링 부하가 증가한다.
      </li>
      <li>
        적은 수의 경우 스케줄러의 부하는 줄어 들지만 병렬성이 줄어 들어 태스크 수행 시간이 더 오래 걸린다.
      </li>
    </ul>
</ul>

<h3>1-5-6. 데이터 지역성</h3>
<ul>
  <li>
    <strong>데이터 지역성(data locality)</strong>은 공유 클러스터 환경에서 중요한 개념으로 네트워크를 통해 데이터 블록을 교환하지 않고 <strong>특정 데이터를 갖는 노드에서 동작</strong>할 수 있도록 지정하는 것을 의미한다.
  </li>
</ul>

<h3>1-5-7. 통계 수집</h3>
<ul>
  <li>
    Spark의 구조적 API를 사용하면 비용 기반 쿼리 옵티마이저가 최적화를 수행한다. 이때 <strong>옵티마이저가 필요로하는 정보</strong>는 <strong>사용 가능한 테이블과 관련된 통계를 수집(그리고 유지)</strong>해야 한다.
  </li>
  <li>
    통계에는 <strong>테이블 수준</strong>과 <strong>컬럼 수준</strong> 두 가지 종류가 있다.
  </li>
  <li>
    통계는 <strong>이름이 지정된 테이블</strong>에서만 사용할 수 있으며 임의의 DataFrame이나 RDD에서는 사용할 수 없다.
  </li>
  <li>
    컬럼 수준의 통계는 수집하는 데 오래 걸리지만 비용 기반 옵티마이저가 사용할 수 있는 <strong>데이터 컬럼과 관련된 정보를 더 많이 제공</strong>한다.
  </li>
  <li>
    통계는 Spark에서 빠르게 성장하는 부분으로 통계에 기반한 다양한 최적화 기법이 계속 추가될 것이다.
  </li>
</ul>

```sql
# 1. 테이블 수준의 통계 수집
ANALYZE TABLE table_name COMPUTE STATISTICS
```

```sql
# 2. 컬럼 수준에서 통계를 수집. (컬럼을 지정한다).
ANALYZE TABLE table_name COMPUTE STATISTICS FOR
COLUMNS comlumn_name1, column_name2, ...
```

<br>

<h2>1-6. 셔플 설정</h2>
<ul>
  <li>
    <strong>외부 shuffle 서비스</strong>를 통해 머신에서 실행되는 익스큐터가 바쁜 상황에서도 <strong>원격 머신</strong>에서 shuffle 데이터를 읽을 수 있어 성능을 높일 수 있다.
  </li>
  <li>
    Shuffle과 관련해서는 여러 설정이 있지만 기본값만으로도 충분하다.
  </li>
  <li>
    직렬화 포맷은 RDD 기반 Spark job 성능에 큰 영향을 미친다. 직렬화를 할 경우 Kryo를 사용하는 것이 좋다.
  </li>
  <li>
    Shuffle을 수행할 때에도 <strong>파티션의 수</strong>를 적절하게 구성하는 것이 중요하다.
  </li>
</ul>

<br>

<h2>1-7. 메모리 부족과 가비지 컬렉션</h2>
<ul>
  <li>
    Spark job 실행 중 익스큐터 혹은 드라이버 머신의 <strong>메모리가 부족</strong>하거나 <strong>메모리 압박(memory pressure)</strong>으로 인해 태스크를 완료하지 못할 수 있다.
  </li>
  <li>
    메모리와 관련된 문제는 주로 다음 세 가지로 인해 발생한다.
  </li>
    <ul>
      <li>
        앱 실행 중 메모리를 너무 많이 사용한 경우
      </li>
      <li>
        가비지 컬렉션이 너무 자주 수행되는 경우
      </li>
      <li>
        JVM 내에 객체가 너무 많이 생성되어 더 이상 사용하지 않는 객체를 가비지 컬렉션이 정리하면서 느려지는 경우.
      </li>
    </ul>
  <li>
    <strong>구조적 API</strong>를 사용하면 <strong>JVM 객체</strong>를 생성하지 않기에 최적화를 할 수 있다.
  </li>
  <li>
    <strong>Spark SQL</strong>은 <strong>내부 포맷</strong>으로 연산을 수행하기 때문에 메모리 압박을 크게 줄일 수 있다.
  </li>
</ul>

<h3>1-7-1. 가비지 컬렉션 영향도 측정</h3>
<ul>
  <li>
    가비지 컬렉션 튜닝의 첫 번째 단계는 가비지 컬렉션의 <strong>발생 빈도</strong>와 <strong>소요 시간</strong>에 대한 <strong>통계</strong>를 모으는 것이다.
  </li>
  <li>
    spark.executor.extraJavaOption 속성에 Spark JVM 옵션으로 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps 값을 추가해 통계를 모을 수 있다.
  </li>
  <li>
    속성값을 설정한 후 Spark job을 실행하면 가비지 컬렉션이 발생할 때마다 <strong>워커의 로그</strong>에 메시지가 출력된다. (로그는 <strong>워커의 stdout 파일</strong>에 저장된다).
  </li>
</ul>

<h3>1-7-2. 가비지 컬렉션 튜닝</h3>
<ul>
  <li>
    JVM 메모리 관리에 대한 기초 지식
  </li>
    <ul>
      <li>
        자바 힙 공간은 <strong>Young 영역</strong>과 <strong>Old 영역</strong>으로 분리된다. <strong>Young 영역</strong>은 <strong>수명이 짧은 객체</strong>를 유지한다. <strong>Old 영역</strong>은 <strong>오래 살아 있는 객체</strong>를 대상으로 한다.
      </li>
      <li>
        Young 영역은 다시 <strong>Eden</strong>, <strong>Survivor1</strong>, <strong>Survivor2</strong> 세 영역으로 나뉜다.
      </li>
    </ul>
  <li>
    가비지 컬렉션 수행 절차
  </li>
    <ul>
      <li>
        <strong>Eden 영역이 가득 차면</strong> Eden 영역에 대한 가비지 컬렉션(minor garbage collection)이 실행된다.<br>→ Eden 영역에서 살아남은 객체와 Survivor1 영역의 객체는 <strong>Survivor2 영역으로 복제</strong>된다.
      </li>
      <li>
        두 Survivor 영역을 <strong>교체</strong>한다.
      </li>
      <li>
        객체가 아주 오래되었거나 Survivor2 영역이 가득 차면 <strong>Old 영역으로 옮겨진다</strong>.
      </li>
      <li>
        Old 영역이 가득 차면 <strong>풀 가비지 컬렉션(full garbage collection)</strong>이 발생한다. 
      </li>
        <ul>
          <li>
            Full garbage collection은 힙 공간의 모든 객체를 추적해 <strong>참조 정보가 없는 객체들을 제거</strong>하고 나머지 객체를 빈 곳으로 옮긴다.
          </li>
          <li>
            Full garbage collection은 <strong>가장 느린</strong> 가비지 컬렉션이다.
          </li>
        </ul>
    </ul>
  <li>
    가비지 컬렉션의 튜닝 목표는 두 가지이다. 하나는 먼저 <strong>수명이 긴 캐시 데이터셋</strong>을 <strong>Old 영역에 저장</strong>하는 것이고 다른 하나는 <strong>Young 영역</strong>에서 수명이 짧은 객체를 보관할 수 있도록 <strong>충분한 공간</strong>을 유지하는 것이다.
  </li>
  <li>
    태스크가 완료되기 전에 풀 가비지 컬렉션이 자주 발생하다면 태스크를 처리하기 위한 메모리 확보를 위해 <strong>캐싱에 사용되는 메모리양</strong>을 줄여야 한다.
  </li>
  <li>
    마이너 가비지 컬렉션은 자주 발생하지만 메이저 가비지 컬렉션이 자주 발생하지 않는 경우 <strong>Eden 영역에 메모리를 더 할당</strong>한다.
  </li>
  <li>
    사용자 태스크가 HDFS에서 데이터를 읽는다면 사용할 데이터의 양은 <strong>HDFS에서 읽을 데이터 블록 크기</strong>로 추정할 수 있다.
  </li>
  <li>
    가비지 컬렉션이 <strong>병목 현상을 발생</strong> 시키고 각 <strong>영역의 크기</strong>를 늘려도 더이상 부하를 줄일 수 없다면 <strong>G1GC 가비지 컬렉션</strong>을 사용하여 성능을 높일 수 있다.
  </li>
    <ul>
      <li>
        힙 메모리 크기를 늘리려면 G1 영역의 크기를 증가시켜야 한다.
      </li>
      <li>
        새로운 설정을 적용한 뒤에는 가비지 컬렉션의 <strong>발생 빈도</strong>와 <strong>소요 시간 변경 추이</strong>를 모니터링해야 한다.
      </li>
    </ul>
  <li>
    저자의 경험적으로 보면 컬렉션 튜닝의 효과는 <strong>앱</strong>과 <strong>사용 가능한 메모리양</strong>에 따라 달라진다.
  </li>
    <ul>
      <li>
        특히 <strong>full garbage collection이 발생하는 빈도</strong>를 줄이면 부하를 줄이는데 많은 도움이 된다.
      </li>
    </ul>
</ul>

<br><br>

<h1>2. 직접적인 성능 향상 기법</h1>
<h2>2-1. 병렬화</h2>
<ul>
  <li>
    특정 stage의 처리 속도를 높이려면 가장 먼저 <strong>병렬성</strong>을 높이는 작업을 시작해야 한다.
  </li>
  <li>
    spark.default.parallelism과 spark.sql.shuffle.partitions의 값을 <strong>클러스터 코어 수</strong>에 따라 설정한다.
  </li>
    <ul>
      <li>
        Stage에서 처리해야 할 데이터양이 매우 많다면 클러스터의 <strong>CPU 코어당 최소 2~3 개</strong>의 태스크를 할당한다.
      </li>
    </ul>
</ul>

<br>

<h2>2-2. 향상된 필터링</h2>
<ul>
  <li>
    Spark job에서 <strong>필터링 과정을 먼저 수행</strong>하는 것은 자주 사용되는 최적화 기법이다.
  </li>
  <li>
    파티셔닝과 버켓팅 기법을 활용하는 것 또한 성능 향상에 많은 도움이 된다.
  </li>
</ul>

<br>

<h2>2-3. 파티션 재분배와 병합</h2>
<ul>
  <li>
    파티션 재분배 과정은 <strong>셔플을 동반</strong>한다. 그럼에도 클러스터 전체에 걸쳐 <strong>데이터가 균등하게 분배</strong>되기에 job 전체 실행 단계를 최적화할 수 있다.
  </li>
  <li>
    Shuffle 대신 동일 노드 파티션을 하나로 합치는 <strong>coalesce 메서드</strong>를 실행해 DataFrame이나 RDD의 <strong>전체 파티션 수</strong>를 먼저 줄여야 한다.
  </li>
    <ul>
      <li>
        repartition 메서드는 위보다 <strong>느리며</strong> 부하를 분산하기 위해 <strong>네트워크로 데이터를 셔플링</strong>한다.
      </li>
    </ul>
  <li>
    파티션 재분배는 <strong>조인</strong>이나 <strong>cache 메서드</strong> 호출 시 매우 유용하다.
  </li>
  <li>
    파티션 재분배 과정은 <strong>부하를 유발</strong>하지만 <strong>앱 전체적인 성능</strong>과 <strong>Spark job 병렬성</strong>을 높일 수 있다.
  </li>
</ul>

<h3>2-3-1. 사용자 정의 파티셔닝</h3>
<ul>
  <li>
    Job이 여전히 느리거나 불안정하게 동작하면 <strong>RDD를 이용한 사용자 정의 파티셔닝 기법</strong>을 적용한다.
  </li>
  <li>
    사용자 정의 파티셔닝 함수를 정의해 <strong>DataFrame보다 더 정밀한 수준</strong>으로 클러스터 전반의 데이터 체계를 제어할 수 있다.
  </li>
</ul>

<br>

<h2>2-4. 사용자 정의 함수(UDF)</h2>
<ul>
  <li>
    <strong>UDF 사용을 최대한 피하는 것</strong> 또한 좋은 최적화 방법이다. <strong>구조적 API</strong>를 최대한 활용하는 것이 가장 좋은 방법이다.
  </li>
  <li>
    Spark는 <strong>UDF에서 대량의 데이터를 한 번에 처리</strong>하는 기능을 개발하고 있다. 해당 기능은 python Pandas 라이브러리의 DataFrame을 사용해 <strong>다수의 레코드를 한 번에 처리</strong>할 수 있는 <strong>벡터화(vectorized) UDF</strong>와 비슷하다.
  </li>
</ul>

<br>

<h2>2-5. 임시 데이터 저장소(캐싱)</h2>
<ul>
  <li>
    앱에서 <strong>같은 데이터셋을 계속해서 재사용</strong>한다면 <strong>캐싱</strong>을 사용해 최적화할 수 있다.
  </li>
    <ul>
      <li>
        데이터를 캐싱할 때 직렬화, 역직렬화 그리고 저장소 자원을 소모하기 때문에 항상 최적의 방안은 아니다.
      </li>
    </ul>
  <li>
    캐싱이 필요한 경우는 <strong>Spark 대화형 세션</strong>이나 <strong>Standalone 앱</strong>에서 <strong>특정 데이터셋(e.g. DataFrame 혹은 RDD)을 다시 사용</strong>하려 할 때이다.
  </li>
  <li>
    캐싱은 <strong>지연 연산</strong>이며 <strong>데이터에 접근</strong>해야 캐싱이 일어난다.
  </li>
  <li>
    <strong>RDD</strong>는 <strong>물리적 데이터</strong>를 캐시에 저장한다. 반면 <strong>구조적 API</strong>의 캐싱은 <strong>물리적 실행 계획</strong>을 기반을 이루어진다.
  </li>
    <ul>
      <li>
        구조적 API는 물리적 실행 계획을 참조하기에 누군가 <strong>먼저 캐시한 버전</strong>이 있는지 주의해야 한다.
      </li>
    </ul>
  <li>
    <strong>캐시 저장소 레벨</strong>은 <strong>p467의 표</strong>를 통해 확인할 수 있다. (혹은 공식 문서).
  </li>
  <li>
    Spark의 cache 명령은 기본적으로 데이터를 <strong>메모리에 저장</strong>한다.
  </li>
  <li>
    더 정교한 캐싱을 위해서는 <strong>persist 메서드</strong>를 사용하여 <strong>캐시 영역을 지정</strong>하는 StorageLevel 객체를 파라미터로 사용한다.
  </li>
</ul>

```python
# 1. 캐싱 없이 DataFrame을 활용하는 코드
DF1 = spark.read.format("csv")\
    .option("inferSchema", "true")\
    .option("header", "true")\
    .load("/workspace/Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv")

# DF1을 활용하여 다른 DF 생성 (캐싱 X).
#   - 캐싱을 활용하지 않기에 비효율적으로 매번 DF1을 읽는다.
DF2 = DF1.groupBy("DEST_COUNTRY_NAME").count().collect()
DF3 = DF1.groupBy("ORIGIN_COUNTRY_NAME").count().collect()
DF4 = DF1.groupBy("count").count().collect()
```

```python
# 2. 캐시를 활용하여 DF1를 캐싱하고 최적화
DF1.cache()

# 지연 처리인 캐시를 count() action을 통해 실행.
DF1.count()
```

```python
# 3. 캐싱된 DF1을 활용하여 다시 작업 수행
DF2 = DF1.groupBy("DEST_COUNTRY_NAME").count().collect()
DF3 = DF1.groupBy("ORIGIN_COUNTRY_NAME").count().collect()
DF4 = DF1.groupBy("count").count().collect()

# 작업 시간이 캐싱을 활용하기 전보다 줄어드는 것을 확인할 수 있다.
```

<br>

<h2>2-6. 조인</h2>
<ul>
  <li>
    조인은 최적화를 위한 <strong>공통 영역</strong>이다.
  </li>
  <li>
    <strong>동등 조인</strong>은 최적화하기 가장 쉽기에 우선적으로 사용하는 것이 좋다. 이후에는 <strong>조인 순서를 최적화</strong>한다.
  </li>
  <li>
    <strong>브로드캐스트 조인 힌트</strong>를 사용하면 Spark가 쿼리 실행 계획을 생성할 때 <strong>지능적으로 계획</strong>을 세울 수 있다.
  </li>
  <li>
    안정성과 최적화를 위해 <strong>카테시안 조인</strong>이나 <strong>전체 외부 조인</strong> 사용은 최대한 피해야한다.
  </li>
  <li>
    <strong>테이블 통계</strong>와 <strong>버켓팅</strong>은 조인 전에 테이블 통계를 수집하여 <strong>Spark가 조인 타입을 결정</strong>하는 데 유용하게 사용된다.
  </li>
  <li>
    데이터를 적절히 <strong>버켓팅</strong>하면 조인 수행 시 <strong>거대한 양의 shuffle</strong>이 발생하지 않도록 미리 방지할 수 있다.
  </li>
</ul>

<br>

<h2>2-7. 집계</h2>
<ul>
  <li>
    <strong>충분히 많은 수의 파티션</strong>을 갖을 수 있도록 데이터를 필터링하는 것이 최선의 방법이다.
  </li>
  <li>
    RDD를 사용하면 집계 수행 방식을 정확하게 제어하고 코드의 성능과 안정성을 개선할 수 있다.
  </li>
</ul>

<br>

<h2>2-8. 브로드캐스트 변수</h2>
<ul>
  <li>
    사용자 앱에서 사용되는 다수의 UDF에서 큰 데이터 조각을 사용한다면 해당 <strong>데이터 조각을 개별 노드에 전송</strong>하여 <strong>읽기 전용 복사본</strong>으로 저장한다.
  </li>
    <ul>
      <li>
        Job마다 데이터 조각을 재전송하는 과정을 건너 뛸 수 있다.
      </li>
    </ul>
  <li>
    <strong>룩업 테이블</strong>이나 <strong>머신러닝 모델</strong>을 저장하는 데 사용할 수 있다.
  </li>
  <li>
    SparkContext를 이용해 <strong>브로드캐스트 변수를 생성</strong>하고 <strong>임의의 객체를 브로드캐스트</strong>한 다음 <strong>태스크에서 참조</strong>하게 만들 수 있다.
  </li>
</ul>