<ul>
  <li>
    이전 내용: <br>구조적 API로 정의한 논리적 연산<br>→ 논리 실행 계획으로 분해<br>→ 물리적 실행 계획으로 변환
  </li>
  <li>
    물리적 실행 계획은 클러스터의 머신에서 실행되는 단위인 RDD 작업으로 구성된다.
  </li>
  <li>
    이번 장에서 배우는 내용
  </li>
    <ul>
      <li>
        Spark 애플리케이션의 <strong>아키텍처</strong>와 <strong>컴포넌트</strong>
      </li>
      <li>
        Spark 내/외부에서 실행되는 <strong>Spark 애플리케이션 생애주기</strong>
      </li>
      <li>
        파이프라이닝과 같은 중요한 <strong>저수준 실행 속성</strong>
      </li>
      <li>
        Spark 애플리케이션을 실행하는 데 <strong>필요한 사항</strong>
      </li>
    </ul>
</ul>

<br>

<h1>1. 스파크 애플리케이션의 아키텍처</h1>
<ul>
  <li>
    <strong>Spark 드라이버</strong>
  </li>
    <ul>
      <li>
        <strong>Spark 드라이버</strong>는 <strong>물리적 머신의 프로세스</strong>이며 클러스터에서 실행 중인 <strong>애플리케이션의 상태를 유지</strong>한다.
      </li>
      <li>
        Spark 애플리케이션의 <strong>운전자 역할</strong>을 하는 프로세스이다.
      </li>
      <li>
        Spark 애플리케이션의 <strong>실행을 제어</strong>, Spark 클러스터(익스큐터와 태스크)의 <strong>모든 상태 정보를 유지</strong>.
      </li>
      <li>
        물리적 컴퓨팅 자원 확보 및 익스큐터 실행을 위해 <strong>클러스터 메니저와 통신</strong>이 가능해야 한다.
      </li>
    </ul>
  <li>
    <strong>Spark 익스큐터</strong>
  </li>
    <ul>
      <li>
        Spark 드라이버가 할당한 <strong>태스크를 수행</strong>하는 프로세스이다.
      </li>
      <li>
        태스크의 상태와 결과(성공 혹은 실패)를 <strong>드라이버에 보고</strong>한다.
      </li>
      <li>
        모든 Spark 애플리케이션은 <strong>개별 익스큐터 프로세스를 활용</strong>한다.
      </li>
    </ul>
  <li>
    <strong>클러스터 매니저</strong>
  </li>
    <ul>
      <li>
        클러스터 매니저는 Spark 애플리케이션을 실행할 <strong>클러스터 머신을 유지</strong>한다.
      </li>
      <li>
        클러스터 매니저는 <strong>드라이버(마스터)</strong>와 <strong>워커</strong>라는 개념을 갖고 있다. 프로세스가 아닌 <strong>물리적인 머신</strong>에 연결되는 개념이다.
      </li>
    </ul>
  <li>
    실제로 Spark 애플리케이션을 실행할 때가 되면 <strong>클러스터 매니저</strong>에 <strong>자원 할당</strong>을 요청한다.
  </li>
    <ul>
      <li>
        앱 설정에 따라 드라이버와 익스큐터에 <strong>필요한 자원을 요청</strong>한다.
      </li>
    </ul>
  <li>
    Spark 앱의 실행 과정에서 클러스터 매니저는 <strong>앱이 실행되는 머신</strong>을 관리한다.
  </li>
  <li>
    Spark가 지원하는 <strong>클러스터 매니저</strong> 세 가지
  </li>
    <ul>
      <li>
        스탠드얼론 클러스터 매니저
      </li>
      <li>
        아파치 메소스
      </li>
      <li>
        하둡 YARN
      </li>
    </ul>
</ul>

<br>

<h2>1-1. 실행 모드</h2>
<ul>
  <li>
    실행 모드는 애플리케이션을 실행할 때 요청한 자원의 <strong>물리적인 위치</strong>를 결정한다.
  </li>
    <ul>
      <li>
        <strong>클러스터 모드</strong>
      </li>
      <li>
        <strong>클라이언트 모드</strong>
      </li>
      <li>
        <strong>로컬 모드</strong>
      </li>
    </ul>
</ul>

<h3>1-1-1. 클러스터 모드</h3>
<ul>
  <li>
    <strong>가장 흔하게</strong> 사용되는 Spark 애플리케이션 모드이다.
  </li>
  <li>
    클러스터 모드를 사용하기 위해서는 컴파일된 <strong>JAR 파일</strong>이나 <strong>파이썬 스크립트</strong> 또는 <strong>R 스크립트</strong>를 <strong>클러스터 매니저에 전달</strong>해야 한다.
  </li>
  <li>
    클러스터 매니저는 스크립트 파일을 받은 후 <strong>워커 노드</strong>에 <strong>드라이버와 익스큐터 프로세스를 실행</strong>한다.
  </li>
  <li>
    <strong>하나의 워커 노드</strong>에 <strong>드라이버</strong>를 할당하고, <strong>다른 워커 노드</strong>에 <strong>익스큐터</strong>를 할당한다.
  </li>
</ul>

<h3>1-1-2. 클라이언트 모드</h3>
<ul>
  <li>
    <strong>클라이언트 머신</strong>이 <strong>Spark 드라이버 프로세스</strong>를 유지하고, <strong>클러스터 매니저</strong>는 <strong>익스큐터 프로세스</strong>를 유지한다. 즉, Spark 앱이 클러스터와 <strong>무관한 머신</strong>에서 동작한다.
  </li>
  <li>
    이때 클러스터에 포함되지 않은 클라이언트 머신을 <strong>게이트웨이 머신(gateway machine)</strong> 또는 <strong>에지 노드(edge node)</strong>라 한다.
  </li>
</ul>

<h3>1-1-3. 로컬 모드</h3>
<ul>
  <li>
    <strong>로컬 모드</strong>로 설정한 경우 모든 Spark 앱은 <strong>단일 머신</strong>에서 실행된다.
  </li>
  <li>
    Spark를 학습하거나 앱 테스트 그리고 개발 중인 앱을 반복적으로 실행하는 용도로 주로 사용한다.
  </li>
</ul>

<br><br>

<h1>2. 스파크 애플리케이션 생애주기(스파크 외부)</h1>
<ul>
  <li>
    <strong>spark-submit</strong> 명령을 사용해 애플리케이션을 실행하는 예제를 다룬다.
  </li>
  <li>
    <strong>하나의 드라이버 노드</strong>와 <strong>세 개의 워커 노드</strong>로 구성된 총 네 대 규모의 클러스터가 이미 실행되고 있음을 가정한다.
  </li>
</ul>

<br>

<h2>2-1. 클라이언트 요청</h2>
<ul>
  <li>
    클라이언트 요청 처리 단계
  </li>
    <ul>
      <li>
        Spark <strong>앱을 제출</strong>. (앱은 컴파일된 JAR 파일이나 라이브러리 파일).<br>
        → 클러스터 매니저에게 애플리케이션 <strong>실행 요청</strong>을 보낸다. (Spark <strong>드라이버 프로세스의 자원</strong>을 함께 요청).<br>
        → 클러스터 매니저는 요청을 받아 클러스터 노드 중 하나에 <strong>드라이버 프로세스</strong>를 띄우고, 이후 드라이버가 Executor 리소스를 요청해 <strong>작업을 수행</strong>한다.<br>
        → Spark Job을 제출한 클라이언 <strong>프로세스가 종료</strong>됨.<br>→ 앱은 <strong>클러스터에서 실행</strong>된다.
      </li>
    </ul>
</ul>

```bash
# 1. Spark app 제출을 위한 터미널 명령
./bin/spark-submit \
--class <main-class> \
--master <master-url> \
--deploy-mode cluster \
--conf <key>=<value> \
... # 다른 옵션
<application-jar> \
[application-arguments]
```

<br>

<h2>2-2. 시작</h2>
<ul>
  <li>
    요청이 완료된 후 드라이버 프로세스가 클러스터에 배치되어 <strong>사용자 코드를 실행</strong>한다.
  </li>
  <li>
    <strong>사용자 코드</strong>는 반드시 Spark 클러스터를 초기화하는 <strong>SparkSession을 포함</strong>해야 한다.
  </li>
    <ul>
      <li>
        SparkSession은 클러스터 매니저와 통신해 <strong>Spark 익스큐터 프로세스의 실행을 요청</strong>한다.
      </li>
    </ul>
  <li>
    사용자는 <strong>spark-submit을 실행</strong>할 때 사용하는 명령행에 인수로 <strong>익스큐터 수</strong>와 <strong>설정값</strong>을 지정할 수 있다.
  </li>
  <li>
    <strong>클러스터 매니저</strong>는 <strong>익스큐터 프로세스를 시작</strong>하고 결과를 받아 <strong>익스큐터의 위치</strong>와 <strong>관련 정보</strong>를 <strong>드라이버 프로세스에 전송</strong>한다.
  </li>
  <li>
    모든 작업이 완료되면 <strong>Spark 클러스터가 완성</strong>된다.
  </li>
</ul>

<br>

<h2>2-3. 실행</h2>
<ul>
  <li>
    Spark 클러스터가 생성된 후 <strong>코드를 실행</strong>한다.
  </li>
  <li>
    드라이버와 워커는 코드를 실행하고 <strong>데이터를 이동</strong>하는 과정에서 <strong>서로 통신</strong>한다.
  </li>
  <li>
    드라이버는 각 워커에 <strong>태스크를 할당</strong>하고 태스크를 할당받은 워커는 <strong>태스크의 상태와 성공/실패 여부</strong>를 드라이버에 전송한다.
  </li>
</ul>

<br>

<h2>2-4. 완료</h2>
<ul>
  <li>
    Spark 앱의 실행이 완료되면 드라이버 프로세스가 <strong>성공 혹은 실패 중 하나의 상태로 종료</strong>된다.
  </li>
  <li>
    드라이버가 종료된 뒤 클러스터 매니저는 드라이버가 속한 <strong>Spark 클러스터의 모든 익스큐터를 종료</strong>다.
  </li>
    <ul>
      <li>
        이 시점에서 Spark 애플리케이션의 성공/실패 여부를 클러스터 매니저에 요청해 확인할 수 있다.
      </li>
    </ul>
</ul>

<br><br>

<h1>3. 스파크 애플리케이션의 생애주기(스파크 내부)</h1>
<ul>
  <li>
    <strong>사용자 코드 관점</strong>에서 생애 주기를 배운다.
  </li>
  <li>
    Spark 앱은 <strong>하나 이상의 Spark Job</strong>으로 구성된다.
  </li>
  <li>
    스레드를 사용해 여러 액션을 병렬로 수행하는 경우가 아니라면 앱의 Spark Job은 <strong>차례대로 실행</strong>된다.
  </li>
</ul>

<br>

<h2>3-1. SparkSession</h2>
<ul>
  <li>
    모든 Spark 앱은 가정 먼저 <strong>SparkSession을 생성</strong>한다.
  </li>
    <ul>
      <li>
        <strong>대화형 모드</strong>에서는 <strong>자동으로 생성</strong>되지만, <strong>앱</strong>을 만드는 경우라면 <strong>직접 생성</strong>해야 한다.
      </li>
    </ul>
  <li>
    <strong>SparkSession의 빌더 메서드</strong>를 사용할 것을 권장.
  </li>
    <ul>
      <li>
        Spark와 Spark SQL 컨텍스트를 new SparkContext 패턴을 사용하는 것보다 <strong>안전</strong>하다.
      </li>
      <li>
        다수의 라이브러리가 세션을 생성하려는 상황에서 <strong>컨텍스트 충돌을 방지</strong>할 수 있다.
      </li>
    </ul>
  <li>
    <strong>SparkSession을 생성</strong>하면 <strong>Spark 코드를 수행</strong>할 수 있다. 모든 저수준 API, 기존 컨텍스트 그리고 관련 설정 정보에 접근할 수 있다.
  </li>
  <li>
    SparkSession 클래스는 <strong>Spark 2.x 이후 버전</strong>에서 사용 가능하다.
  </li>
</ul>

```python
# 1. SparkSession 클래스를 import (스파크 SQL의 진입점)
from pyspark.sql import SparkSession

spark = SparkSession.builder\
    # 실행 모드 지정 ("local" → 로컬 머신에서 실행)
    .master("local")\
    # 애플리케이션 이름 설정
    .appName("Word Count")\
    # 추가 환경 설정(key, value)
    .config("spark.some.config.option", "some-value")\
    # 기존 세션이 있으면 가져오고, 없으면 새로 생성
    .getOrCreate()
```

<h3>3-1-1. SparkContext</h3>
<ul>
  <li>
    SparkSession의 <strong>SparkContext</strong>는 <strong>Spark 클러스터에 대한 연결</strong>을 나타낸다.
  </li>
  <li>
    SparkContext로 <strong>RDD, accumulator 그리고 broadcast 변수</strong>를 생성하고 <strong>코드를 실행</strong>할 수 있다.
  </li>
  <li>
    SparkSession으로 SparkContext에 접근할 수 있기에 <strong>명시적으로 SparkContext를 초기화할 필요는 없다</strong>.
  </li>
    <ul>
      <li>
        직접 초기화하는 가장 일반적인 방법은 <strong>getOrCreate 메서드</strong>를 사용하는 것이다.
      </li>
    </ul>
  <li>
    과거에는 SparkContext와 SQLContext라는 두 개의 컨텍스트가 존재하였지만 2.x 이후 부터는 SparkSession만 활용하면 된다.
  </li>
</ul>

```scala
// 1. SparkContext 초기화
import org.apache.spark.SparkContext

val sc = SparkContext.getOrCreate()
```

<br>

<h2>3-2. 논리적 명령</h2>
<ul>
  <li>
    Spark 코드는 <strong>transformation</strong>과 <strong>action</strong>으로 구성된다.
  </li>
  <li>
    DataFrame과 같은 <strong>선언적 명령</strong>을 사용하는 방법과 <strong>논리적 명령이 물리적 실행 계획으로 어떻게 변환</strong>되는지 이해하는 것은 중요하다.
  </li>
</ul>

<h3>3-2-1. 논리적 명령을 물리적 실행 계획으로 변환하기</h3>
<ul>
  <li>
    DataFrame을 이용해 파티션을 재분배하는 잡, transformation을 수행하는 잡, 집계 및 최종 결과를 얻어내는 잡 세 단계의 잡을 수행한다.
  </li>
  <li>
    collect와 같은 action을 호출하면 개별 stage와 task로 이루어진 spark job이 실행된다.
  </li>
  <li>
    Spark job은 localhost:4040의 Spark UI에서 확인할 수 있다.
  </li>
</ul>

```python
# 1. 실습을 위한 데이터 생성.
# partitions = 8
#   - range는 기본적으로 8 개의 파티션을 생성한다.
df1 = spark.range(2, 10000000, 2)
df2 = spark.range(2, 10000000, 4)

# 파티션 재분배
# partitions = 5
step1 = df1.repartition(5)
# partitions = 6
step12 = df2.repartition(6)

# id 값을 5배로 변환
# partitions = 5
#   - 위의 설정을 따름
step2 = step1.selectExpr("id * 5 as id")

# 두 DataFrame을 id 컬럼 기준으로 조인
# partitions = 6
#   - 위의 설정을 따름.
step3 = step2.join(step12, ["id"])

# id 컬럼의 합계를 계산
# partition = 200
#   - spark.sql.shuffle.partitions가 200개의 파티션이 기본.
step4 = step3.selectExpr("sum(id)")

# 4. 액션 실행 → 실제 연산이 수행되고 결과를 로컬 드라이버로 수집
step4.collect()
```

```python
# 2. 실행 계획 확인
step4.explain()
```

<br>

<h2>3-2-2. 스파크 잡</h2>
<ul>
  <li>
    보통 <strong>액션 하나</strong>당 <strong>하나의 Spark job</strong>이 생성되며 <strong>action은 항상 결과를 반환</strong>한다.
  </li>
  <li>
    <strong>Spark job</strong>은 <strong>stage</strong>로 나뉘며 <strong>stage의 수</strong>는 <strong>shuffle 작업</strong>이 얼마나 많이 발생하는지에 따라 달라진다.
  </li>
  <li>
    이전 예제의 job
  </li>
    <ul>
      <li>
        Stage 1: task 8개
      </li>
      <li>
        Stage 2: task 8개
      </li>
      <li>
        Stage 3: task 5개
      </li>
      <li>
        Stage 4: task 6개
      </li>
      <li>
        Stage 5: task 200개
      </li>
      <li>
        Stage 6: task 1개
      </li>
    </ul>
</ul>

<br>

<h2>3-4. 스테이지</h2>
<ul>
  <li>
    Spark의 <strong>Stage</strong>는 다수의 머신에서 연산을 수행하는 <strong>태스크 그룹</strong>을 나타낸다.
  </li>
  <li>
    Spark는 <strong>최대한 많은 태스크(job의 transformation)</strong>를 <strong>동일한 stage</strong>로 묶으려 노력한다.
  </li>
  <li>
    <strong>Shuffle 작업</strong>이 일어난 다음에는 반드시 <strong>새로운 stage</strong>를 시작한다.
  </li>
    <ul>
      <li>
        <strong>Shuffle</strong>은 데이터의 <strong>물리적 재분배</strong> 과정이다.
      </li>
      <li>
        <strong>파티션을 재분배</strong>하는 과정은 <strong>데이터를 이동</strong>시키는 작업이기에 <strong>익스큐터 간의 조정</strong>이 필요하다.
      </li>
    </ul>
  <li>
    huffle이 발생하면 데이터가 <strong>한 번 섞이기</strong> 때문에 Spark는 <strong>새로운 Stage</strong>로 나누어 실행하고, 최종 결과를 위해 <strong>이전 Stage와의 의존성을 추적</strong>한다.
  </li>
  <li>
    경험적으로 익스큐터 수보다 <strong>파티션의 수</strong>를 더 크게 지정하는 것이 좋다.
  </li>
</ul>

<br>

<h2>3-5. 태스크</h2>
<ul>
  <li>
    Spark의 스테이지는 <strong>task</strong>로 구성된다.
  </li>
  <li>
    각 task는 단일 익스큐터에서 실행할 <strong>데이터의 블록</strong>과 <strong>다수의 transformation의 조합</strong>으로 볼 수 있다.
  </li>
  <li>
    Task는 데이터 단위(파티션)에 적용되는 <strong>연산 단위</strong>를 의미한다.
  </li>
  <li>
    Task의 수는 파티션의 수를 따라가며 파티션 수를 늘리면 <strong>더 높은 병렬성</strong>을 얻을 수 있다.
  </li>
</ul>

<br><br>

<h1>4. 세부 실행 과정</h1>
<ul>
  <li>
    Spark의 stage와 task는 알아두면 좋을 중요한 특징들을 갖는다.
  </li>
    <ul>
      <li>
        Spark는 <strong>map 연산 후 다른 map 연산</strong>이 이어질 경우 함께 실행할 수 있도록 <strong>stage와 task를 자동으로 연결</strong>한다.
      </li>
      <li>
        Spark는 모든 <strong>shuffle 작업</strong>을 할 때 데이터를 <strong>안정적인 저장소(e.g. 디스크)에 저장</strong>하기에 <strong>여러 job에서 재사용</strong>할 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>4-1. 파이프라이닝</h2>
<ul>
  <li>
    Spark는 <strong>메모리나 디스크에 데이터를 쓰기 전</strong> 최대한 많은 단계를 수행하기 때문에 <strong>인메로리 컴퓨팅 도구</strong>로 사용할 수 있다.
  </li>
  <li>
    Spark의 주요 최적화 기법 중 하나는 <strong>RDD</strong>나 RDD보다 더 아래에서 발생하는 <strong>파이프라이닝</strong>이다.
  </li>
  <li>
    파이프라이닝은 노드 간의 데이터 <strong>이동 없이</strong> 각 노드가 데이터를 <strong>직접 공급</strong>할 수 있는 연산만 모아 task의 <strong>단일 stage</strong>로 만든다.
  </li>
    <ul>
      <li>
        단계별로 메모리나 디스크에 <strong>중간 결과</strong>를 기록하지 않기에 훨씬 처리 속도가 빠르다.
      </li>
      <li>
        <strong>DataFrame</strong>이나 <strong>SQL 연산</strong>에서도 동일한 파이프라이닝 유형이 적용된다.
      </li>
    </ul>
  <li>
    Spark 런타임에서 파이프라이닝을 <strong>자동으로 수행</strong>하기 때문에 앱을 개발할 때에는 눈에 보이지 않는다.
  </li>
    <ul>
      <li>
        Spark UI나 로그 파일로 앱을 확인하면 다수의 RDD 또는 DataFrame 연산이 <strong>하나의 stage</strong>로 파이프라이닝 되어 있음을 알 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>4-2. 셔플 결과 저장</h2>
<ul>
  <li>
      Spark가 reduceByKey와 같이 <strong>노드 간 데이터 이동</strong>을 유발하는 연산을 실행하면 <strong>네트워크에서 Shuffle</strong>이 발생한다.
  </li>
  <li>
      이때 각 키의 입력 데이터를 <strong>여러 노드로부터 복사</strong>해 오며, 소스 태스크는 <strong>Shuffle 결과</strong>를 <strong>로컬 디스크에 셔플 파일로 기록</strong>한다.
  </li>
  <li>
    기록이 끝난 뒤 그룹화나 리듀스를 수행하는 <strong>새로운 Stage</strong>가 시작되고, 이 Stage는 <strong>셔플 파일을 읽어</strong> 연산을 진행한다.
  </li>
  <li>
    셔플 파일이 <strong>로컬에 저장</strong>되므로, Job이 실패하더라도 해당 Stage부터 <strong>재실행</strong>할 수 있다.
  </li>
  <li>
    Shuffle 결과는 디스크에 저장되므로 <strong>새로운 Job에서 재사용</strong>될 수 있는데, 이는 <strong>성능 최적화</strong>를 위한 것이며, 다만 <strong>데이터 갱신이 필요하거나 디스크 부하·파일 유실</strong>이 발생할 경우 <strong>부작용</strong>으로 작용할 수 있다.
  </li>
  <li>
    소스와 관련된 <strong>shuffle이 다시 수행되지 않는 경우</strong> Spark UI와 로그 파일에서는 <strong>skipped</strong>라고 표시된 <strong>사전 셔플 스테이지(pre-suffle stage)</strong>를 확인할 수 있다.
  </li>
  <li>
    더 나은 성능을 위해 <strong>DataFrame</strong>이나 <strong>RDD의 cache 메서드</strong>를 활용할 수 있다. 사용자는 <strong>직접 캐싱</strong>을 수행할 수 있고 어떤 데이터가 <strong>어디에 저장되는지 제어</strong>할 수 있다.
  </li>
</ul>