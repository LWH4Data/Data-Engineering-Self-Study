```
ㅓGLASS') >= 1 as is_glass")\
    .groupBy("is_glass")\
    .count()\
    .collect()

# - "localhost:4040/executors/"에서 결과를 확인할 수 있다.
# - Spark 3.x를 실습으로 사용하고 있고 AQE(Adaptive Query Execution)을 사용하기에 최적
#   화가 진행된다.
#   → 따라서 책보다 더 적은 task가 수행된다.
```

<h3>기타 스파크 UI 탭</h3>
<ul>
  <li>
    <strong>Storage</strong>: 클러스터에 개시된 <strong>RDD</strong> 혹은 <strong>DataFrame</strong> 관련 정보를 제공한다. 시간이 지나 <strong>캐시된 데이터</strong>가 사라졌는지 확인해 볼 수 있다.
  </li>
  <li>
    <strong>Environment</strong>: 클러스터에 설정된 다양한 Spark 속성과 Scala와 Java 관련 정보 등 <strong>런타임 환경 관련 정보</strong>를 제공한다.
  </li>
</ul>

<h3>스파크 UI 설정하기</h3>
<ul>
  <li>
    다양한 속성을 사용해 Spark UI를 설정할 수 있다. 대다수의 설정은 <strong>네트워크 관련 속성</strong>이며 <strong>Spark UI 동작 방식</strong>도 설정할 수 있다.
  </li>
  <li>
    자세한 내용은 Spark 공식문서의 Spark UI 설정표 참고.
  </li>
</ul>

<br>

<h2>4-1. 스파크 REST API</h2>
<ul>
  <li>
    <strong>REST API</strong>를 사용해서 <strong>Spark 상태와 메트릭</strong>을 확인할 수도 있다.
  </li>
  <li>
    REST API의 주소는 <strong>http://localhost:4040/api/v1/<리소스></strong>이다.
  </li>
  <li>
    Spark에서 제공하는 <strong>시각화 및 모니터링 도구</strong>는 REST API를 기반으로 만들어졌다.
  </li>
  <li>
    대부분 REST API는 Spark UI와 동일한 정보를 제공하지만 <strong>SQL 관련 정보</strong>는 제공하지 않는다.
  </li>
  <li>
    Spark UI에서 <strong>볼 수 있는 정보</strong>를 기반으로 사용자 정의 리포트 솔루션을 구축할 때에는 REST API를 사용해야한다. (출처가 REST API이기 때문).
  </li>
</ul>

<br>

<h2>4-2. 스파크 UI 히스토리 서버</h2>
<ul>
  <li>
    Spark UI는 SparkContext가 실행되는 동안 사용할 수 있으며 <strong>종료된 시점</strong>에 앱의 정보를 확인하려면 <strong>Spark History Server</strong>를 이용해야 한다.
  </li>
    <ul>
      <li>
        <strong>이벤트 로그</strong>를 저장하도록 스파크 앱을 설정하면 Spark 히스토리 서버를 이용해 <strong>Spark UI</strong>와 <strong>REST API</strong>를 재구성할 수 있다.
      </li>
    </ul>
  <li>
    Spark 히스토리 서버를 사용하기 위해서는 <strong>특정 경로에 이벤트 로그를 저장</strong>하도록 spark 앱을 설정해야 한다.
  </li>
    <ul>
      <li>
        spark.eventLog.enabled 속성을 true로 설정
      </li>
      <li>
        spark.eventLog.dir 속성에 이벤트 로그 저장 경로 지정.
      </li>
      <li>
        이벤트 로그가 저장되면 Spark 히스토리 서버를 Standalone 앱 형태로 실행할 수 있다.
      </li>
    </ul>
  <li>
    Spark 히스토리 서버는 저장된 이벤트 로그를 기반으로 <strong>웹 UI를 자동으로 재구성</strong>한다.
  </li>
  <li>
    일부 클러스터 매니저와 클라우드 서비스에는 로깅을 자동으로 설정하고 히스토리 서버를 기본적으로 설정한다.
  </li>
</ul>

<br><br>

<h1>5. 디버깅 및 스파크 응급 처치</h1>
<h2>5-1. 스파크 애플리케이션이 시작되지 않는 경우</h2>
<h3>5-1-1. 징후와 증상</h3>
<ul>
  <li>
    Spark 잡이 시작되지 않는다.
  </li>
  <li>
    Spark UI가 드라이버 노드를 제외한 클러스터의 노드 정보를 전혀 표시하지 않는다.
  </li>
  <li>
    Spark UI가 잘못된 정보를 표시하는 것 같다.
  </li>
</ul>

<h3>5-1-2. 잠재적 대응법</h3>
<ul>
  <li>
    설정한 <strong>포트</strong>로 클러스터 머신 간에 <strong>통신</strong>할 수 있는지 확인한다. 보안 요건이 엄격한 경우가 아니라면 <strong>워커 노드 간 모든 포트</strong>를 여는 것이 좋다.
  </li>
  <li>
    Spark <strong>자원 설정</strong>이 올바른지 <strong>클러스터 매니저</strong>가 Spark를 실행할 수 있도록 적합하게 설정되어있는지 확인한다.
  </li>
    <ul>
      <li>
        보통 클러스터가 매니저가 제공할 수 있는 <strong>메모리 자원 이상</strong>으로 익스큐터의 메모리 자원을 요청하는 경우가 많다.
      </li>
      <li>
        따라서 <strong>클러스터 매니저의 UI</strong>로 유휴 자원을 확인한 뒤 spark-submit 명령에 할당할 <strong>메모리를 설정</strong>한다.
      </li>
    </ul>
</ul>

<br>

<h2>5-2. 스파크 애플리케이션 실행 전에 오류가 발생한 경우</h2>
<h3>5-2-1. 징후와 증상</h3>
<ul>
  <li>
    명령이 전혀 실행되지 않으며 오류 메시지가 출력된다.
  </li>
  <li>
    Spark UI에서 job, stage, task의 정보를 확인할 수 없다.
  </li>
</ul>

<h3>5-2-2. 잠재적 대응법</h3>
<ul>
  <li>
    <strong>코드상의 문제</strong>를 먼저 살펴보기 위해 <strong>Spark가 반환하는 오류</strong>를 살펴보아야 한다.
  </li>
  <li>
    클러스터의 드라이버, 워커 그리고 사용하는 저장소 시스템 간의 <strong>네트워크 연결 상태</strong>를 다시 한번 확인한다.
  </li>
  <li>
    <strong>라이브러리나 클래스패스를 확인</strong>한다. 문제가 재현될 때까지 사용자 앱의 로직을 <strong>하나씩 제거</strong>하면서 원인 찾는다.
  </li>
</ul>

<br>

<h2>5-3. 스파크 애플리케이션 실행 중에 오류가 발생한 경우</h2>
<h3>5-3-1. 징후와 증상</h3>
<ul>
  <li>
    하나의 Spark job이 전체 클러스터에서 성공적으로 실행되지만 <strong>다음 job은 실패</strong>.
  </li>
  <li>
    여러 단계로 처리되는 쿼리의 특정 단계가 실패.
  </li>
  <li>
    어제 정상 동작한 예약 작업이 오늘은 실패
  </li>
  <li>
    오류 메시지를 해석하기 어려움.
  </li>
</ul>

<h3>5-3-2. 잠재적 대응법</h3>
<ul>
  <li>
    <strong>데이터의 존재 여부</strong>와 데이터가 <strong>올바른 포맷</strong>인지 확인한다.
  </li>
  <li>
    쿼리 실행 즉시 오류가 발생하다면 <strong>쿼리 실행 계획</strong>을 만드는 단계의 오류일 가능성이 높다. 즉, <strong>쿼리와 관련된 오류</strong>일 가능성이 크다.
  </li>
  <li>
    <strong>어떤 컴포넌트</strong>가 연관되어 있는지를 분석해 단서를 쫒는다.
  </li>
  <li>
    <strong>입력 데이터</strong>와 <strong>데이터 포맷</strong>을 한 번 더 확인한다.
  </li>
  <li>
    Job의 task가 잠시 실행되다가 비정상적으로 종료된다면 <strong>데이터 자체</strong>의 문제일 수 있다.
  </li>
  <li>
    <strong>데이터를 처리하는 코드</strong>에서 오류가 발생할 수 있으며 Spark UI에 task의 상태가 failed로 출력된다. <strong>로그 파일</strong>을 추적해 문제를 해결한다.
  </li>
</ul>

<br>

<h2>5-4. 느리거나 뒤쳐진 태스크</h2>
<h3>5-4-1. 징후와 증상</h3>
<ul>
  <li>
    Spark stage에서 대부분의 태스크가 정상적으로 실행되고 <strong>남은 task가 오랫동안 실행</strong>된다.
  </li>
  <li>
    Spark UI는 느린 태스크를 확인할 수 있으며 <strong>동일한 데이터셋</strong>을 다룰 때 문제가 항상 발생한다.
  </li>
  <li>
    <strong>여러 stage</strong>에서 번갈아 가며 <strong>두 번째 증상이 반복</strong>된다.
  </li>
  <li>
    Spark 앱을 실행하는 <strong>머신 수</strong>를 늘려도 개선되지 않는다.
  </li>
  <li>
    Spark 매트릭을 보면 <strong>특정 익스큐터</strong>가 다른 익스큐터에 비해 <strong>더 많은 데이터를 읽거나 쓰고</strong> 있다.
  </li>
</ul>

<h3>5-4-2. 잠재적 대응법</h3>
<ul>
  <li>
    태스크 간 <strong>데이터 불균형</strong>을 확인한다.
  </li>
  <li>
    <strong>파티션의 수</strong>를 늘려 파티션별 데이터 양을 줄인다.
  </li>
  <li>
    다른 컬럼을 조합해 <strong>파티션을 재분배</strong>한다. (작업의 선수 순서 고려).
  </li>
  <li>
    <strong>익스큐터의 메모리를 증가</strong>.
  </li>
  <li>
    <strong>익스큐터 문제</strong> 모니터링 후 문제 식별 시 해당 머신의 <strong>다른 job</strong>도 문제가 있는지 확인. 클러스터에 <strong>비정상적인 익스큐터나 머신</strong>이 있는지 확인.
  </li>
  <li>
    조인이나 집계 시 문제가 발생한다면 <18.5.5>와 <18.5.6> 참고
  </li>
  <li>
    사용자 정의 함수를 구현할 때 객체 할당이나 비즈니스 로직에서 <strong>쓸모없는 부분</strong> 확인. 가능하면 <strong>DataFrame으로 리팩토링</strong>.
  </li>
  <li>
    사용자 정의 함수(UDF) 혹은 사용자 정의 집계 함수(UDAF)가 <strong>적당한 크기의 데이터</strong>를 사용하는지 확인. 집계 연산은 공통 키와 관련된 많은 데이터를 메모리에 적재하기에 느리다.
  </li>
  <li>
    <strong>투기적 실행(speculative execution)</strong>을 사용하여 더 빠른 노드에서 작업을 수행할 수 있으나 <strong>더 많은 자원을 소모</strong>하고, 멱등성을 보장하지 않으면 <strong>중복저장 문제</strong>가 있다.
  </li>
  <li>
    Dataset은 <strong>가비지 컬렉션</strong>이 빈번하게 발생하여 느릴 수 있다. Spark UI의 가비지 컬렉션 메트릭을 확인한다.
  </li>
</ul>

<br>

<h2>5-5. 느린 집계 속도</h2>
<h3>5-5-1. 징후와 증상</h3>
<ul>
  <li>
    groupBy 호출 시 느린 태스크가 발생한다.
  </li>
  <li>
    집계 처리 이후의 잡도 느리다.
  </li>
</ul>

<h3>5-5-2. 잠재적 대응법</h3>
<ul>
  <li>
    <strong>집계 연산 전에 파티션 수를 증가</strong>시키면 태스크별로 처리할 키를 줄일 수 있다.
  </li>
  <li>
    익스큐터의 <strong>메모리를 증가</strong>시키면 <strong>많은 키</strong>를 처리하기에 느려질 수 있지만 <strong>디스크에 저장하는 빈도</strong>가 줄어 이전보다 빨라질 수도 있다.
  </li>
  <li>
    집계 처리가 끝나고 <strong>이어지는 태스크가 느리다면</strong> 집계 처리된 데이터셋에 불균형 현상이 남아 있을 수 있음으로 <strong>repartition 명령을 추가</strong>한다.
  </li>
  <li>
    <strong>모든 필터와 SELECT 구문</strong>을 집계 연산보다 먼저하면 필요한 데이터만 활용하기에 속도가 빨르다. <strong>구조적 API</strong>는 쿼리 옵티마이저가 자동적으로 해준다.
  </li>
  <li>
    <strong>null 값에 대체 값</strong>을 사용하면 Spark는 null 값을 건너뛰기위한 최적화를 수행할 수 없기에 <strong>느려진다</strong>.
  </li>
  <li>
    일부 집계 함수는 다른 집계 함수에 비해 <strong>태상적으로 느리다</strong>.
  </li>
</ul>

<br>

<h2>5-6. 느린 조인 속도</h2>
<h3>5-6-1. 징후와 증상</h3>
<ul>
  <li>
    조인 스테이지의 처리 시간이 오래 걸린다. 하나 이상의 태스크가 여기에 해당할 수 있다.
  </li>
  <li>
    조인 전후의 스테이지는 정상적으로 동작한다.
  </li>
</ul>

<h3>5-6-2. 잠재적 대응법</h3>
<ul>
  <li>
    많은 조인 연산을 <strong>다른 조인 타입</strong>으로 바꾸어 최적화한다.
  </li>
  <li>
    <strong>조인 순서를 변경</strong>하여 잡의 처리 속도가 올라가는지 확인한다. (각각의 조인 연산 방식을 고려).
  </li>
  <li>
    조인을 수행하기 전 <strong>데이터셋을 분할</strong>하면 클러스터 노드 간 데이터 이동을 줄일 수 있다. <strong>사전조인 파티셔닝(prejoin partitioning)</strong> 기법 실험. (단, 조인 연산은 <strong>shuffle 부하</strong>를 일으킨다).
  </li>
  <li>
    <strong>데이터 치우침 현상</strong>으로 느린 조인이 유발될 수 있다. Spark 앱이나 익스큐터의 <strong>자원 할당량을 늘리는 방법</strong>을 시도해 볼 수 있다.
  </li>
  <li>
    모든 필터와 SELECT 문이 <strong>조인보다 먼저 수행</strong>되도록 구성해볼 수 있다.
  </li>
  <li>
    <strong>null 값을 대체 값</strong>으로 사용하고 있는지 확인한다.
  </li>
  <li>
    Spark는 <strong>입력 DataFrame</strong>이나 <strong>테이블에 대한 통계</strong>가 없는 경우 <strong>브로드캐스트 조인</strong>을 사용 하는 <strong>실행계획을 생성하지 못한다</strong>.
  </li>
</ul>

<br>

<h2>5-7. 느린 읽기와 쓰기 속도</h2>
<h3>5-7-1. 징후와 증상</h3>
<ul>
  <li>
    분산 파일 시스템이나 외부 시스템의 데이터를 읽는 속도가 느리다.
  </li>
  <li>
    네트워크 파일 시스템이나 blob 저장소에 데이터를 쓰는 속도가 느리다.
  </li>
</ul>

<h3>5-7-2. 잠재적 대응법</h3>
<ul>
  <li>
    Spark의 <strong>투기적 실행(spark.speculation 속성을 true로 설정)</strong>을 사용하면 느린 읽기와 쓰기 속도 개선에 도움이 될 수 있다. 
  </li>
    <ul>
      <li>
        투기적 실행이란 첫 번째 태스크에서 발생한 문제가 일시적인지 확인하기 위해 <strong>동일한 연산을 수행</strong>하는 태스크를 추가로 수행하는 방법이다.
      </li>
    </ul>
  <li>
    Spark 클러스터와 저장소 시스템 간의 네트워크 대역폭이 충분하지 않을 수 있기 때문에 <strong>네트워크 성능</strong>을 확인한다.
  </li>
  <li>
    단일 클러스터에서 Spark와 HDFS 같은 분산 파일 시스템을 함께 구성하려면 클러스터의 노드마다 분산 파일 시스템 모두 <strong>동일한 호스트명</strong>을 인식하는지 확인한다.
  </li>
</ul>

<br>

<h2>5-8. 드라이버 OutOfMemoryError 또는 응답 없음</h2>
<h3>5-8-1. 징후와 증상</h3>
<ul>
  <li>
    Spark 앱이 응답하지 않거나 비정상적으로 종료된다.
  </li>
  <li>
    드라이버 로그에 OutOfMemoryError 또는 가비지 컬렉션과 관련된 메시지가 출력된다.
  </li>
  <li>
    명령이 장시간 실행되거나 실행되지 않는다.
  </li>
  <li>
    반응이 거의 없다.
  </li>
  <li>
    드라이버 JVM의 메모리 사용량이 많다.
  </li>
</ul>

<h3>5-8-2. 잠재적 대응법</h3>
<ul>
  <li>
    사용자 코드에서 collect 메서드와 같은 연산을 실행하여 <strong>너무 큰 데이터셋</strong>을 <strong>드라이버에 전송</strong>하려 했을 수 있다.
  </li>
  <li>
    <strong>브로드캐스트</strong>하기 너무 큰 데이터를 브로드캐스트 조인에 사용했을 수 있다.
  </li>
  <li>
    Java의 <strong>jmap 도구</strong>를 통해 <strong>힙 메모리의 히스토그램</strong>을 확인하여 드라이버 <strong>JVM의 메모리</strong>를 가장 많이 차지하는 객체를 찾을 수 있다. 그러나 jamp은 실행 시 <strong>JVM이 잠시 중단</strong>될 수 있어 주의가 필요하다.
  </li>
  <li>
    가능하면 더 많은 데이터를 다룰 수 있도록 드라이버의 <strong>가용 메모리를 증가</strong>시킨다.
  </li>
  <li>
    JVM 메모리 부족 현상은 파이썬과 같은 <strong>다른 언어</strong>를 사용할 때 발생할 수 있다. 두 언어 간의 <strong>데이터 변환 과정</strong>에서 과도한 메모리가 사용되기 때문이다.
  </li>
    <ul>
      <li>
        언어 문제인이 확인하기 위해 드라이버 노드에 <strong>더 적은 양의 데이터를 전송</strong>해보거나 드라이버 메모리에 모으지 않고 <strong>파일로 저장</strong>해 볼 수 있다.
      </li>
    </ul>
  <li>
    SQL JDBC 서버와 노트북 환경을 이용해 다른 상용자와 <strong>SparkContext를 공유</strong>하는 상황이라면 여러 사용자가 <strong>동시에 드라이버 메모리로 전송할 수 있는 명령어</strong>를 실행하지 못하게 해야한다.
  </li>
</ul>

<h2>5-9. 익스큐터 OutOfMemoryError 또는 응답없음.</h2>
<h3>5-9-1. 징후와 증상</h3>
<ul>
  <li>
    익스큐터 로그에 OutOfMemoryError 또는 가비지 컬렉션과 관련된 메시지가 출력되며 Spark UI에서도 확인할 수 있다.
  </li>
  <li>
    익스큐터가 비정상적으로 종료되거나 응답하지 않는다.
  </li>
  <li>
    특정 노드의 느린 태스크가 복구되지 않는다.
  </li>
</ul>

<h3>5-9-2. 잠재적 대응법</h3>
<ul>
  <li>
    익스큐터의 <strong>가용 메모리</strong>와 익스큐터 <strong>수</strong>를 증가시킨다.
  </li>
  <li>
    관련 파이썬 설정을 변경해 <strong>PySpark 워커의 크기를 증가</strong>시킨다.
  </li>
  <li>
    <strong>익스큐터 로그</strong>에 <strong>가비지 컬렉션 오류 메시지</strong>가 발생했는지 확인한다.
  </li>
    <ul>
      <li>
        실행 중인 태스크의 일부가 <strong>너무 많은 객체</strong>를 생성하고 있으면 가비지 컬렉션이 발생할 확률이 높다.
      </li>
      <li>
        특히 <strong>사용자 정의 함수</strong>를 사용하는 경우 발생할 확률이 높다.
      </li>
      <li>
        데이터 <strong>파티션을 재분배</strong>하면 병렬성을 높일 수 있다.
      </li>
    </ul>
  <li>
    null 값을 <strong>대체값</strong>으로 사용하는지 확인한다.
  </li>
  <li>
    RDD와 Dataset은 객체를 생성하기에 문제가 발생할 가능성이 더 크다. 가능하면 <strong>구조적 API</strong>를 사용하는 것이 더 좋다.
  </li>
  <li>
    Java의 <strong>jmap 도구</strong>를 활용하여 익스큐터 힙 메모리의 히스토리를 통해 <strong>가장 많은 메모리</strong>를 사용하는 클래스를 확인한다.
  </li>
  <li>
    key-value 저장소와 같이 <strong>다른 워크로드를 처리하는 노드</strong>에 익스큐터가 위치한다면 Spark job을 <strong>다른 노드에 분리</strong>해야 한다.
  </li>
</ul>

<br>

<h2>5-10. 의도하지 않은 null 값이 있는 결과 데이터</h2>
<h3>5-10-1. 징후와 증상</h3>
<ul>
  <li>
    transformation이 실행된 결과에 의도치 않은 null 값이 발생한다.
  </li>
  <li>
    잘 동작하던 운영 환경의 예약 작업이 더는 동작하지 않거나 정확한 결과를 생성하지 못한다.
  </li>
</ul>

<h3>5-10-2. 잠재적 대응법</h3>
<ul>
  <li>
    비즈니스 로직을 변경하지 않았다면 <strong>데이터 포맷이 변경</strong>되었을 수 있다. 이는 이전에 동작했던 코드가 더는 동작하지 않음을 의미한다.
  </li>
  <li>
    <strong>Accumulator</strong>를 사용해 <strong>레코드</strong>나 <strong>특정 데이터 타입의 수</strong>를 확인할 수 있다.
  </li>
    <ul>
      <li>
        Accumulator로 <strong>정상과 비정상 레코드 수</strong>를 확인할 수 있다.
      </li>
    </ul>
  <li>
    transformation이 실제 유효한 <strong>쿼리 실행 계획</strong>을 생성하는지 확인한다.
  </li>
</ul>

<br>

<h2>5-11. 디스크 공간 없음 오류</h2>
<h3>5-11-1. 징후와 증상</h3>
<ul>
  <li>
    <strong>no space left on disk 오류 메시지</strong>와 함께 <strong>job이 실패</strong>한다.
  </li>
</ul>

<h3>5-11-2. 잠재적 대응법</h3>
<ul>
  <li>
    더 많은 디스크 공간을 확보한다.
  </li>
  <li>
    데이터 치우침 현상이 발생하면 일부 노드의 저장소 공간이 모두 소진될 수 있다. 이런 경우 <strong>파티션을 재분배</strong> 하는 것이 좋다.
  </li>
  <li>
    몇 가지 저장소 설정을 실험해본다.
  </li>
  <li>
    문제가 되는 머신의 <strong>오래된 로그 파일</strong>과 <strong>셔플 파일</strong>을 수동으로 제거한다.
  </li>
</ul>

<br>

<h2>5-12. 직렬화 오류</h2>
<h3>5-12-1. 징후와 증상</h3>
<ul>
  <li>
    직렬화 오류와 함께 잡이 실패한다.
  </li>
</ul>

<h3>5-12-2. 잠재적 대응법</h3>
<ul>
  <li>
    <strong>구조적 API</strong>를 사용하는 경우 직렬화 오류는 거의 발생하지 않는다.
  </li>
    <ul>
      <li>
        UDF나 RDD를 이용해 개발된 <strong>사용자 정의 로직</strong>을 <strong>수행하는 익스큐터</strong>에서는 발생할 수 있다.
      </li>
      <li>
        직렬화가 불가한 경우에도 발생한다.
      </li>
    </ul>
</ul>

앞 부분 조금 날라가서 다시 작성해야 한다.