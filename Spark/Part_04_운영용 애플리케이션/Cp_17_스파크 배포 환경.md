<ul>
  <li>
    Spark 앱 실행에 필요한 <strong>인프라 구조</strong>를 알아본다.
  </li>
    <ul>
      <li>
        클러스터 배포 시 선택사항
      </li>
      <li>
        Spark가 지원하는 클러스터 매니저
      </li>
      <li>
        배포 시 고려사항과 배포 환경 설정
      </li>
    </ul>
  <li>
    Spark가 지원하는 클러스터 매니저들의 <strong>근본적인 차이점</strong>을 살펴보고 Spark 공식 사이트에서 제공하는 관련자료 소개.
  </li>
  <li>
    세 가지 공식 클러스터 매니저
  </li>
    <ul>
      <li>
        스탠드얼론 모드
      </li>
      <li>
        하둡 YARN
      </li>
      <li>
        아파치 메소스
      </li>
    </ul>
  <li>
    클러스터 매니저는 Spark 앱을 배포해 실행할 수 있는 클러스터의 머신을 유지하고 관리한다.
  </li>
</ul>

<br><br>

<h1>1. 스파크 애플리케이션 실행을 위한 클러스터 환경</h1>
<ul>
  <li>
    Spark 클러스터를 구성할 수 있는 환경은 크게 두 가지로 나뉜다.
  </li>
    <ul>
      <li>
        <strong>설치형 클러스터(on-premise cluster)</strong>
      </li>
      <li>
        <strong>공개 클라우드(public cloud)</strong>
      </li>
    </ul>
</ul>

<br>

<h2>1-1. 설치형 클러스터 배포 환경</h2>
<ul>
  <li>
    <storng>자체 데이터센터</storng>를 운영하는 조직 외에는 설치형 클러스터 방식을 활용하면 <storng>trade-off</storng>가 존재한다.
  </li>
  <li>
    <storng>온프레미스 환경</storng>이기에 특정 워크로드 최적화가 가능하지만 다음과 같은 문제를 갖는다.
  </li>
    <ul>
      <li>
        설치형 클러스터의 크기는 제한적이지만 분석 워크로드에 필요한 자원은 <storng>상황에 따라 다르다</storng>.
      </li>
      <li>
        HDFS 혹은 분산 key-value 저장소 같은 자체 저장소 시스템을 사용하기에 <storng>지리적 복제(geo relication)</storng> 및 <storng>재해 복구(disaster recovery)체계</storng>도 함께 구축해야한다.
      </li>
    </ul>
  <li>
    <storng>설치형 클러스터</storng>를 사용할 때 <storng>자원 활용 문제</storng>를 해결할 수 있는 가장 좋은 방법이 <storng>클러스터 매니저</storng>이다.
  </li>
    <ul>
      <li>
        클러스터 매니저를 통해 <storng>다수의 Spark 앱을 실행</storng>하고 앱의 <storng>자원을 동적으로 재할당</storng> 할 수 있다. (하나의 클러스터에서 Spark 앱이 아닌 앱도 실행 가능).
      </li>
      <li>
        <storng>YARN과 메소스</storng>는 <storng>동적 자원 공유</storng>를 스탠드얼론보다 잘 지원하고 <storng>Spark 외의 앱</storng>도 실행 가능하다.
      </li>
      <li>
        단, <storng>공개 클라우드</storng>를 사용하면 <storng>앱에 맞는 규모</storng>의 클러스터를 얻을 수 있다.
      </li>
      <li>
        설치형 클러스터를 사용하면 <storng>여러 종류의 저장소</storng>를 선택한 수 있다. (요즘은 <storng>클라우드의 발달</storng> 예를 들어 S3 등으로 <storng>의미가 없는 것 같다</storng>).
      </li>
    </ul>
</ul>

<br>

<h2>1-2. 클라우드 배포 환경</h2>
<ul>
  <li>
    클라우드 환경을 사용하면 <strong>자원을 탄력적으로 늘이고 줄이는 것</strong>이 가능하다. 성능이 크게 필요하다면 필요한 만큼 확장하면 된다.
  </li>
  <li>
    공개 클라우드는 <strong>비용이 저렵</strong>하고 <strong>지리적 복제 기능</strong>을 지원하는 저장소를 제공하기에 대규모 데이터를 쉽게 관리할 수 있다.
  </li>
    <ul>
      <li>
        <strong>아마존 S3</strong>, 에저 Blob 저장소, 구글 클라우드 저장소와 같이 클러스터에서 분리된 글로벌 저장소 시스템을 사용하고 Spark 워커로드마다 별도의 클러스터를 동적으로 할당하는 것이 좋다.
      </li>
      <li>
        <strong>저장소는 동일</strong>하게 사용하고 <strong>클러스터만 달라지기</strong>에 필요한 연산에 필요할 때에만 <strong>바꾸어 가면서</strong> 활용이 가능하다.
      </li>
      <li>
        클라우드 환경을 사용하면 설치형 클러스터 환경 처럼 <strong>연산 관련 환경을 관리할 필요가 없다</strong>.
      </li>
    </ul>
  <li>
    <strong>클라우드 환경</strong>을 사용한다면 해당 장의 내용 다수가 필요없다. 이 경우 <strong>스탠드얼론 매니저</strong>를 사용하는 것이 좋다.
  </li>
</ul>

<br><br>

<h1>2. 클러스터 매니저</h1>
<ul>
  <li>
    클라우드 환경을 사용하지 않으면 Spark를 사용하기 위한 <strong>클러스터 매니저</strong>를 선택해야 한다.
  </li>
</ul>

<br>

<h2>2-1. 스탠드얼론 모드</h2>
<ul>
  <li>
    <strong>Spark 스탠드얼론</strong>은 <strong>Spark 워크로드용</strong>으로 특별히 제작된 경량화 플랫폼이다.
  </li>
  <li>
    스탠드얼론 클러스터 매니저를 사용해 <strong>하나의 클러스터에서 다수의 Spark 앱</strong>을 실행할 수 있다.
  </li>
  <li>
    실행을 위한 간단한 <strong>인터페이스</strong>를 제공하며 <strong>대형 Spark 워크로드에 확장</strong>할 수 있다.
  </li>
  <li>
    스탠드얼론은 다른 클러스터 매니저보다 <strong>제한적인 기능</strong>을 갖는다.
  </li>
    <ul>
      <li>
        Spark <strong>앱만 실행할 수 있다</strong>는 단점이 있지만 클러스터 환경을 빠르게 구축하여 사용하기에는 좋다.
      </li>
      <li>
        YARN이나 메소스를 사용한 경험이 없을 때 사용하기 좋다.
      </li>
    </ul>
</ul>

<h3>2-1-1. 스탠드얼론 클러스터 시작하기</h3>
<ul>
  <li>
    <strong>네트워크 환경</strong>에서 클러스터를 구성하는 노드끼리 통신할 수 있어야함을 의미하기에 실행할 버전의 Spark를 <strong>전체 노드에 설치</strong>해야한다.
  </li>
  <li>
    모든 노드에 설치했다면 Spark에 내장된 <strong>스크립트</strong>를 이용해 클러스터를 실행할 수 있다.
  </li>
  <li>
    코드를 통해 클러스터 매니저의 마스터 프로세스를 실행하면 <strong>spark://HOST:PORT 형식의 URI</strong>가 출력된다.
  </li>
    <ul>
      <li>
        마스터 프로세스의 <strong>URI</strong>는 <strong>워커노드를 실행할 때</strong> 사용된다.
      </li>
    </ul>
  <li>
    <strong>클러스터 애플리케이션 초기화</strong> 시 <strong>SparkSession의 --master 인수</strong>로 <strong>마스터 프로세스 URI</strong>를 사용할 수 있다.
  </li>
  <li>
    <strong>마스터 프로세스 UI</strong>에서 <strong>마스터 프로세스의 URI</strong>를 활인할 수 있다.
  </li>
    <ul>
      <li>
        마스터 프로세스의 기본 UI 주소는 <strong>http://master-ip-address:8080</strong>이다.
      </li>
    </ul>
  <li>
    클러스터를 실행할 머신에 로그인한 뒤 실행시킬 스크립트와 마스터 프로세스 URI를 입력해 워커 노드를 시작한다.
  </li>
    <ul>
      <li>
        마스터 노드는 워커 노드와 네트워크 통신이 가능해야 하며 마스터 프로세스 URI의 포트역시 열려 있어야 한다.
      </li>
    </ul>
  <li>
    <strong>전체 워커 노드</strong>에서 스크립트를 실행해 <strong>Spark 클러스터를 사용</strong>할 수 있다.
  </li>
</ul>

```bash
# 1. 모든 노드를 준비(Spark 설치) 했다면 수동으로 클러스터의 노드 중 하나를 다음 명령을 사
#    용해 마스터 프로세스로 실행한다.
$SPARK_HOME/sbin/start-master.sh
```

```bash
# 2. 워커 노드에서 스크립트 실행. (3.x 버전 이후로 리팩토링.)
$SPARK_HOME/sbin/start-worker.sh spark://<master-host>:7077
```

<h3>2-1-2. 스크립트를 이용한 스탠드얼론 클러스터 시작하기</h3>
<ul>
  <li>
    시작 스크립트를 설정해 Standalone 클러스터의 시작을 <strong>자동화</strong>할 수 있다.
  </li>
    <ul>
      <li>
        자동화를 위해서는 SPark가 설치된 디렉터리 하위에 <strong>conf/slaves 파일</strong>을 생성한다.
      </li>
      <li>
        slaves 파일에 <strong>Spark 워커</strong>로 사용할 <strong>모든 머신의 호스트명</strong>을 한 줄에 하나씩 기록한다.
      </li>
      <li>
        해당 파일이 없으면 데몬이 로컬에서 실행된다.
      </li>
    </ul>
  <li>
    실제로 클러스터를 실행할 때 마스터 머신은 워커 머신에 <strong>SSH(secure Shell)</strong>를 통해 접근한다.
  </li>
    <ul>
      <li>
        SSH는 <strong>병렬로 실행</strong>되며 개인 키(private key)를 이용해 <strong>비밀번호 없이</strong> 로그인하는 방식(password-less)을 사용한다.
      </li>
      <li>
        SSH를 사용할 수 없다면 <strong>SPARK_SSH_FOREGROUND 환경 변수</strong>를 설정해 워커 노드에 접속할 때마다 <strong>비밀번호를 입력</strong>한다.
      </li>
    </ul>
  <li>
    slaves 파일을 설정한 뒤 하둡 배포 스크립트 기반의 다음 <strong>shell 스크립트</strong>를 사용해 클러스터를 <strong>시작하거나 중지</strong>할 수 있다. 스크립트는 <strong>$SPARK_HOME/sbin</strong> 디렉터리에 들어있다.
  </li>
    <ul>
      <li>
        <strong>$SPARK_HOME/sbin/start-master.sh</strong>
      </li>
        <ul>
          <li>
            스크립트를 실행한 머신에서 마스터 인스턴스를 시작.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/start-slaves.sh</strong>
      </li>
        <ul>
          <li>
            conf/slaves 파일에 명시된 각 머신에서 슬레이브 인스턴스를 시작한다.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/start-slave.sh</strong>
      </li>
        <ul>
          <li>
            스크립트를 실행한 머신에서 슬레이브 인스턴스를 시작한다.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/start-all.sh</strong>
      </li>
        <ul>
          <li>
            마스터 인스턴스를 시작하고 conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 시작한다.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/stop-master.sh</strong>
      </li>
        <ul>
          <li>
            bin/start-master.sh 스크립트로 시작한 마스터 인스턴스를 중지시킨다.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/stop-slaves.sh</strong>
      </li>
        <ul>
          <li>
            conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 중지시킨다.
          </li>
        </ul>
      <li>
        <strong>$SPARK_HOME/sbin/stop-all.sh</strong>
      </li>
        <ul>
          <li>
            마스터 인스턴스를 중지시키고 conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 중지시킨다.
          </li>
        </ul>
    </ul>
</ul>

<h3>2-1-3. 스탠드얼론 클러스터 설정</h3>
<ul>
  <li>
    Standalone은 앱 튜닝에 필요한 여러 설정을 갖으며 종료된 앱의 <strong>워커별 작업 파일</strong>부터 <strong>워커의 코어</strong>와 <strong>메모리</strong>까지 <strong>모든 것을 제어</strong>한다.
  </li>
  <li>
    설정은 환경변수나 앱의 속성에서 정의하며 Spark 공식 문서의 Standalone 환경변수 표를 참조.
  </li>
</ul>

<h3>2-1-4. 애플리케이션 제출하기</h3>
<ul>
  <li>
    클러스터를 생성하면 <strong>URI(spark://로 시작하는 주소)</strong>를 이용해 마스터 노드나 spark-submit 명령을 사용할 수 있는 <strong>머신에서 앱을 제출</strong>할 수 있다.
  </li>
</ul>

<br>

<h2>2-2. YARN에서 스파크 실행하기</h2>
<ul>
  <li>
    <strong>하둡 YARN</strong>은 <strong>job 스케줄링</strong>과 <strong>클러스터 자원 관리용</strong> 프레임워크이다.
  </li>
  <li>
    Spark는 기본적으로 하둡 YARN 클러스터를 매니저로 지원하지만 하둡 자체가 필요하지 않으며 하둡 에코 시스템에도 포함되지 않는다.
  </li>
  <li>
    <strong>spark-submit 명령</strong>의 <strong>--master 인수</strong>를 <strong>yarn</strong>으로 지정해 하둡 YARN 클러스터에서 Spark job을 실행할 수 있다.
  </li>
  <li>
    하둡 YARN은 다양한 실행 프레임워크를 지원하는 통합 스케줄러로 Standalone보다 많은 기능을 제공한다.
  </li>
  <li>
    YARN 클러스터 구성은 책의 범위를 벗어나기에 생략.
  </li>
</ul>

<h3>2-2-1. 애플리케이션 제출하기</h3>
<ul>
  <li>
    YARN 클러스터가 다른 배포 환경과 갖는 가장 큰 차이는 <strong>--master 인수가 yarn</strong> 이라는 것이다.
  </li>
  <li>
    Spark는 <strong>HADOOP_CONF_DIR</strong> 혹은 <strong>YARN_CONF_DIR 환경변수</strong>를 통해 YARN 설정 파일을 찾는다.
  </li>
    <ul>
      <li>
        환경변수를 하웁의 환경 설정 디렉터리로 설정하면 spark-submit 명령을 실행할 수 있다.
      </li>
    </ul>
  <li>
    YARN은 두 가지 배포 모드를 제공한다. 하나는 <strong>cluster모드</strong>이고 다른 하나는 <strong>client 모드</strong>이다.
  </li>
  <li>
    <strong>cluster 모드</strong>는 YARN 클러스터에서 Spark 드라이버 프로세스를 관리하고 <strong>client는 앱을 생성</strong>한 다음 <strong>즉시 종료</strong>된다.
  </li>
  <li>
    client 모드는 드라이버가 <strong>클라이언트 프로세스에서 실행</strong>된다. 따라서 YARN은 마스터 노드를 관리하지 않고 앱에 <strong>익스큐터 자원을 배분</strong>하는 역할만 한다.
  </li>
  <li>
    <strong>cluster 모드</strong>는 Spark 앱을 실행한 노드가 아닌 <strong>다른 노드</strong>에서 Spark job이 실행될 수 있다. 
  </li>
    <ul>
      <li>
        따라서 라이브러리와 외부 jar 파일을 클러스터 노드에 <strong>수동으로 배포<.strong>하거나 spark-submit 명령의 <strong>--jar 인수에 명시해 배포</strong>해야 한다.
      </li>
    </ul>
  <li>
    spark-submit 명령을 사용할 때 설정할 수 있는 <strong>YARN 고유 속성</strong> 몇 가지가 있으며 <strong>우선순위 큐와 보안에 필요한 keytab 파일</strong>을 제어할 수 있다.
  </li>
</ul>

<br>

<h2>2-3. YARN 환경의 스파크 애플리케이션 설정하기</h2>
<h3>2-3-1. 하둡 설정</h3>
<ul>
  <li>
    Spark를 이용해 HDFS의 파일을 읽고 쓰려면 Spark 클래스패스에 <strong>두 개의 하둡 설정 파일</strong>을 포함해야 한다. 
  </li>
    <ul>
      <li>
        <strong>hdfs-site.xml</strong>: HDFS 클라이언트의 <strong>동작 방식</strong>을 결정.
      </li>
      <li>
        <strong>core-site.xml</strong>: 기본 파일 시스템의 <strong>이름</strong>을 설정.
      </li>
    </ul>
  <li>
    하둡 버전에 따라 위치가 다르지만 보통 <strong>/etc/hadoop/conf</strong> 하위에 설정 파일이 존재한다.
  </li>
  <li>
    Spark에서 <strong>하둡 설정 파일</strong>을 사용하려면 <strong>$SPARK_HOME/spark-env.sh 파일의 HADOOP_CONF_DIR 변숫값</strong>을 하둡 설정 파일 경로로 지정하거나 spark-submit 명령을 사용해 <strong>앱을 실행할 때 환경변수</strong>로 지정해야 한다.
  </li>
</ul>

<h3>2-3-2. YARN 애플리케이션 속성</h3>
<ul>
  <li>
    하둡 설정이나 기능 중 YARN의 실행과 보안에 관련된 설정은 Spark에 영향을 미치며 관련 설정은 <strong>Spark 공식 문서에서 YARN 설정 표</strong>를 참고.
  </li>
</ul>

<br>

<h2>2-4. 메소스에서 스파크 실행하기</h2>
<ul>
  <li>
    <strong>Apache Mesos</strong>는 CPU, 메모리, 저장소 그리고 다른 연산 자원을 머신에서 <strong>추상화</strong>한다. 이를 통해 <strong>내고장성(foult-tolerance)</strong> 및 <strong>탄력적 분산 시스템(elastic distributed system)</strong>을 쉽게 구성하고 효과적으로 실행할 수 있다.
  </li>
  <li>
    Mesos는 Spark와 같이 <strong>짧게 실행되는 앱</strong>을 관리할 수 있다.
  </li>
  <li>
    Mesos는 Spark에서 지원하는 클러스터 매니저 중 <strong>가장 무겁다</strong>. 따라서 환경이 구축되어 있는 경우에만 사용하는 것이 좋다.
  </li>
  <li>
    Mesos는 두 가지 모드로 Spark를 실행할 수 있다. 하나는 fine-grained이고, 다른 하나는 coarse-grained 모드이다. 현재는 <strong>coarse-grained 모드</strong>만 사용한다.
  </li>
  <li>
    <strong>coarse-grained 모드</strong>는 Spark 익스큐터를 <strong>단일 Mesos 태스크</strong>로 실행하며 Spark 익스큐터는 다음과 같은 앱 속성에 따라 크기가 조정된다.
  </li>
    <ul>
      <li>
        spark.executor.memory
      </li>
      <li>
        spark.executor.cores
      </li>
      <li>
        spark.cores.max / spark.executor.cores
      </li>
    </ul>
</ul>

<h3>2-4-1. 애플리케이션 제출하기</h3>
<ul>
  <li>
    Mesos 또한 다른 클러스터 매니저와 유사한 방식으로 제출이 가능하며 <strong>cluster 모드 방식</strong>이 가장 좋다.
  </li>
  <li>
    <strong>client 모드</strong>는 클러스터 분산 자원 관리와 관련된 <strong>추가 설정</strong>이 필요하며 드라이버와 Mesos 클러스터가 <strong>통신</strong>할 수 있도록 spark-env.sh 파일에 설정 정보를 추가</strong>해야 한다.
  </li>
</ul>

```bash
# 1. spark-env.sh에 다음과 같이 환경변수 선언
#   - libmesos.so 파일은 일반적으로 <prefix>/lib/libmesos.so에 위치.
#       - <prefix>는 기본적으로 /usr/local 이다.
export MESOS_NATIVE_JAVA_LIBRARY=<libmesos.so 파일의 경로>
```

```scala
// 2. spark.executor.uri 속성을 통해 앱 실행.
//     - <업로드한 spark-2.2.0.tar.gz 파일의 URL> 지정.
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder
  .master("mesos://HOST:5050")
  .appName("my app")
  .config("spark.executor.uri", "<업로드한 spark-2.2.0.tar.gz 파일의 URL>")
  .getOrCreate()
```

<h3>2-4-2. 메소스 설저하기</h3>
<ul>
  <li>
    메소스와 관련된 설정은 <strong>Spark 공식 문서에서 메소스 설정 표</strong>를 참고.
  </li>
</ul>

<br>

<h2>2-5. 보안 관련 설정</h2>
<ul>
  <li>
    Spark는 신뢰가 낮은 환경에서 앱을 안전하게 실행할 수 있도록 <strong>API 기능을 </strong>제공한다.
  </li>
  <li>
    보안 설정은 대부분 Spark <strong>외부 실행 환경</strong>과 관련이 있으며 주로 <strong>통신 방식</strong>과 관련있다.
  </li>
  <li>
    인증, 네트워크 그리고 TLS와 SSL을 설정할 수 있으며 자세한 것은 Spark 공식 문서 보안 설정 표 참고.
  </li>
</ul>

<br>

<h2>2-6. 클러스터 네트워크 설정</h2>
<ul>
  <li>
    클러스터 노드 사이에서 <strong>proxy</strong>를 사용하기 위해 Spark 클러스에 <strong>사용자 정의 배포 설정</strong>을 적용하는 경우 도움이 된다.
  </li>
  <li>
    Spark의 성능을 올리고 싶다면 사용자가 정의한 배포 시나리오에 맞게 적용해야 한다.
  </li>
  <li>
    자세한 설명은 Spark 공식 문서 네트워킹 설정 표 참고.
  </li>
</ul>

<br>

<h2>2-7. 애플리케이션 스케줄링</h2>
<ul>
  <li>
    각 Spark 앱은 <strong>독립적인 익스큐터 프로세스</strong>를 실행하며 클러스터 매니저는 <strong>Spark 앱 전체에 스케줄링 기능</strong>을 제공한다.
  </li>
  <li>
    Spark 앱에서 여러 개의 job을 <strong>다른 스레드가 제출</strong>한 경우 <strong>동시에 실행</strong>이 가능하다.
  </li>
  <li>
    Spark는 앱에서 <strong>자원을 스케줄링</strong> 할 수 있도록 <strong>페어 스케줄러(fair scheduler)</strong> 기능을 제공한다.
  </li>
  <li>
    모든 클러스터 매니저에서 사용할 수 있는 간단한 방법은 자원을 <strong>고정된 크기</strong>로 나누는 것이고, 이를 통해 각 앱이 사용할 수 있는 <strong>최대 자원이 결정</strong>된다.
  </li>
  <li>
    <strong>동적 할당기능</strong>을 이용하면 대기 중인 <strong>태스크 수</strong>에 따라 앱을 동적으로 확장하고 축소할 수 있다.
  </li>
</ul>

<h3>2-7-1. 동적 할당</h3>
<ul>
  <li>
    <strong>하나의 클러스터에서 여러 Spark 앱을 실행</strong>하려면 워크로드에 따라 앱이 점유하는 <strong>자원을 동적으로 조정</strong>해야 한다.
  </li>
  <li>
    해당 기능은 <strong>모든 클러스터 매니저</strong>에서 사용할 수 있으며 기본은 사용하지 않음이다.
  </li>
  <li>
    설정은 클러스터 매니저마다 다르며 <strong>Spark 공식 문서의 동적 할당 설정 표</strong>를 참고.
  </li>
</ul>

<br><br>

<h1>3. 기타 고려사항</h1>
<ul>
  <li>
    애플리케이션의 개수와 유형을 고려해야 한다.
  </li>
    <ul>
      <li>
        <strong>YARN</strong>
      </li>
        <ul>
          <li>
            YARN은 HDFS를 사용할 경우 적합하지만 외의 경우는 그렇지 않다.
          </li>
          <li>
            HDFS 정보를 사용하도록 설계되어 클라우드 환경을 제대로 지원하지 못한다.
          </li>
          <li>
            연산용 클러스터와 저장소 클러스터가 강하게 결합되어 있다. (클러스터 확장 시 동시 확장 필요).
          </li>
        </ul>
      <li>
        <strong>Mesos</strong>
      </li>
        <ul>
          <li>
            YARN을 조금 더 개선하였지만 무겁기 때문에 앱 실행만을 할 경우 의미가 없다.
          </li>
        </ul>
      <li>
        <strong>Standalone</strong>
      </li>
        <ul>
          <li>
            가장 가벼우며 이해가 비교적 쉽다. 단, <strong>더 많은 앱</strong>을 관리하는 인프라 구조는 YARN이나 Mesos를 사용하는 것이 좋다.
          </li>
        </ul>
    </ul>
  <li>
    <strong>다양한 Spark 버전</strong>으로 구성된 Spark 앱을 실행하려면 버전별 설정 스크립트를 관리해야 하기에 어렵다. 이때는 필요시 <strong>Spark 버전 제한</strong>을 걸어야 한다.
  </li>
  <li>
    YARN과 Mesos는 <strong>디버깅용 log</strong>를 지원하지만 <strong>Standalone은 약간의 수정</strong>이 필요하다.
  </li>
  <li>
    테이블 카탈로그(table catalog) 같은 <strong>저장된 데이터셋의 메타데이터</strong>를 관리하기 위해 <strong>메타스토어(metastore) 사용</strong>을 고려해야 한다.
  </li>
  <li>
    워크로드의 특성에 맞춰 <strong>외부 셔플 서비스</strong>를 사용해야 할 수도 있다. 외부 셔플을 사용하면 Spark가 셔플 블록을 로컬 디스크에 저장하지 않고 <strong>외부에 저장</strong>한다.
  </li>
    <ul>
      <li>
        따라서 <strong>익스큐터를 임의로 제거(kill)</strong>해도 다른 앱에서 <strong>shuffle 결과를 재사용</strong>할 수 있다.
      </li>
    </ul>
</ul>