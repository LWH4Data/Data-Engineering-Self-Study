<h1>1. 발행/구독 메시지 전달</h1>
<ul>
  <li>
    <strong>발행/구독 메시지 전달(pubish/subscribe messaging)</strong>과 <strong>데이터 주도 애플리케이션</strong>의 중요성을 이해해야 한다.
  </li>
    <ul>
      <li>
        발행/구독 메시지 전달(publish/subscribe messaging) 패턴의 특징은 데이터를 보낼 때 직접 수신자에게 보내지 않는다. 대신 <strong>전송자</strong>가 메시지를 <strong>분류</strong>해서 보내면 <strong>수신자</strong>는 분류된 메시지를 <strong>구독</strong>한다.
      </li>
    </ul>
  <li>
    발행/구독 시스템에는 대개 발행된 메시지를 전달받고 <strong>중계</strong>해주는 중간 지점 역할을 하는 <strong>브로커(broker)</strong>가 있다.
  </li>
</ul>

<br>

<h2>1-1. 초기의 발행/구독 시스템</h2>
<ul>
  <li>
    많은 발행/구독 패턴을 따르는 사례들은 가운데 간단한 <strong>메시지 큐</strong>나 프로세스 간 <strong>통신 채널</strong>을 놓는 유사한 패턴을 갖는다.
  </li>
  <li>
    중간 단계가 없다면 각 애플리케이션을 개별로 연결하여 데이터를 받아야하며 앱이 추가될 때마다 점점 연결이 복잡해진다. 이때 <strong>모든 애플리케이션으로부터 지표를 받는 하나의 애플리케이션</strong>을 만들고 모든 질의 요청을 처리하게 한다면 개별 앱에 연결해야하는 <strong>복잡성</strong>을 줄일 수 있다.
  </li>
    <ul>
      <li>
        위의 구조가 메시지 발행/구독 시스템이다.
      </li>
    </ul>
</ul>

<br>

<h2>1-2. 개별 메시지 큐 시스템</h2>
<ul>
  <li>
    로그 또한 동일하게 개별 앱으로 요청을 보내는 것이 아니라 중앙의 서버에서 통합적으로 저장하고 모든 요청을 처리하는 발행/구독 시스템을 사용하면 이점이 많다.
  </li>
    <ul>
      <li>
        즉, point-to-point 연결 방식보다 중간 서버를 사용하면 복잡한 연결을 피할 수 있다.
      </li>
      <li>
        단, <strong>중복</strong>이 많을 수 있으며 <strong>버그와 한계가 제각각</strong>인 다수의 데이터 큐 시스템을 유지 관리해야 한다는 문제 등이 존재한다.
      </li>
    </ul>
</ul>

<br><br>

<h1>2. 카프카 입문</h1>
<ul>
  <li>
    앞선 문제를 개선하기 위해 고안된 메시지 발행/구독 시스템이 <strong>Kafka</strong>이다. Kafka는 <strong>분산 커밋 로그</strong> 혹은 <strong>분산 스트리밍 플랫폼</strong>이라고 불리기도 한다.
  </li>
  <li>
    파일시스템이나 데이터베이스 커밋 로그(commit log)는 모든 트랜잭션 기록은 지속성(durable) 있게 보존하여 시스템의 상태를 일관성(consistency) 있게 복구할 수 있도록 고안되었다.
  </li>
    <ul>
      <li>
        <strong>Kafka</strong>는 저장된 데이터의 <strong>순서</strong>를 유지한 채로 <strong>지속성</strong> 있게 보관되며 <strong>결정적(deterministic)</strong>으로 읽을 수 있다.
      </li>
      <li>
        <strong>Kafka</strong>는 <strong>확장</strong>시 성능을 향상시키고 <strong>실패</strong>가 발생하여도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 <strong>분산시켜 저장</strong>할 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>2-1. 메시지와 배치</h2>
<ul>
  <li>
    Kafka에서 데이터의 기본 단위는 <strong>메시지(message)</strong>다.
  </li>
    <ul>
      <li>
        메시지는 DB의 row나 record와 유사해 보일 수 있다.
      </li>
      <li>
        Kafka 입장에서 메시지는 <strong>단순한 바이트의 배열</strong>일 뿐 특정한 형식이나 의미는 없다.
      </li>
    </ul>
  <li>
    메시지는 <strong>키(key)</strong>라 불리는 <strong>메타데이터</strong>를 포함할 수 있다.
  </li>
    <ul>
      <li>
        키 또한 Kafka의 입장에서는 의미가 없는 <strong>바이트 배열</strong>일 뿐이다.
      </li>
      <li>
        키는 메시지를 저장할 <strong>파티션을 결정</strong>하기 위해 사용된다.
      </li>
        <ul>
          <li>
            간단한 방법으로는 <strong>'key에서 생성된 hash 값 %(나머지 연산) 토픽의 파티션 수'</strong>에 해당하는 파티션에 메시지를 저장하는 것이다.
          </li>
        </ul>
    </ul>
  <li>
    Kafka는 효율성을 위해 메시지를 <strong>배치(batch)</strong> 단위로 저장한다.
  </li>
    <ul>
      <li>
        배치란 그저 같은 토픽의 파티션에 쓰여지는 <strong>메시지들의 집합</strong>일 뿐이다.
      </li>
      <li>
        배치는 <strong>지연(latency)</strong>과 <strong>처리량(throughput)</strong> 사이에 <strong>trade-off</strong>를 발생시킨다.
      </li>
        <ul>
          <li>
            배치 크기가 클수록 시간당 처리되는 메시지의 수는 늘어나지만, 각각의 메시지가 전달되는 데 걸리는 시간도 증가한다.
          </li>
        </ul>
      <li>
        배치는 더 효율적인 데이터 전송과 저장을 위해 약간의 처리 능력을 들여서 <strong>압축</strong>되는 경우가 많다.
      </li>
    </ul>
</ul>

<br>

<h2>2-2. 스키마</h2>
<ul>
  <li>
    Kafka에게 있어 메시지는 단순한 바이트 배열이지만, 내용을 이해하기 쉽도록 일정한 <strong>스키마</strong>를 부여하는 것이 권장된다.
  </li>
    <ul>
      <li>
        스키마에는 JSON(JavaScript Object Notation)이나 XML(eXtensilbe Markup Language)등이 있으나 타입 처리 기능이나 호환성 유지 기능이 떨어져 많은 Kafka 개발자들은 <strong>Avro</strong>를 선호한다.
      </li>
        <ul>
          <li>
            Avro는 조밀한 <strong>직렬화 형식</strong>을 제공한다.
          </li>
          <li>
            Avro는 메시지 본체와 스키마를 분리하기에 <strong>스키마가 변경</strong> 되어도 코드를 생성할 필요가 없다.
          </li>
          <li>
            Avro는 강력한 데이터 타이핑(typing)과 스키마 변경에 따른 <strong>상위 호환성</strong>과 <strong>하휘 호환성</strong> 또한 지원한다.
          </li>
        </ul>
    </ul>
  <li>
    Kafka는 메시지 쓰기와 읽기 작업을 분리할 수 있도록 하기위해 <strong>일관적인 데이터 형식</strong>이 중요하다.
  </li>
  <li>
    스키마와 직렬화에 대해서는 3장에서 자세히 다룬다.
  </li>
</ul>

<br>

<h2>2-3. 토픽과 파티션</h2>
<ul>
  <li>
    Kafka에 저장되는 메시지는 <strong>토픽(topic)</strong> 단위로 분류된다.
  </li>
    <ul>
      <li>
        DB의 테이블 혹은 파일시스템의 폴더와 유사하다.
      </li>
    </ul>
  <li>
    토픽은 다시 여러 개의 <strong>파티션(partition)</strong>으로 나뉘어 진다.
  </li>
    <ul>
      <li>
        파티션은 하나의 로그에 해당한다. 이때의 로그는 일반적인 백엔드 서버의 로그가 아니라, 이벤트가 순서대로 append되는 <strong>Kafka의 커밋 로그(commit log)</strong>를 의미한다.
      </li>
      <li>
        파티션에 메시지가 쓰여질 때에는 <strong>추가만 가능(append-only)</strong>한 형태로 쓰여진다.
      </li>
      <li>
        로그를 읽을 때에는 맨 앞부터 제일 끝까지 <strong>순서대로</strong> 읽는다.
      </li>
      <li>
        토픽 안의 여러 파티션 간의 순서는 보장하지 않지만, 각 파티션 내부의 <strong>레코드들의 순서</strong>는 보장된다.
      </li>
      <li>
        각 파티션은 다른 서버에 저장딜 수 있기에 하나의 서버의 용량을 넘어 여러 개의 서버로 <strong>수평적 확장</strong>될 수 있다.
      </li>
      <li>
        파티션은 서로 다른 서버들이 동일한 파티션의 <strong>복제본을 저장</strong>할 수 있기에 <strong>중복</strong>될 수 있다. 따라서 하나의 <strong>서버에 장애</strong>가 발생하여도 대응이 가능하다.
      </li>
    </ul>
  <li>
    Kafka와 같은 시스템을 이야기할 때에는 <strong>스트림(stream)</strong>이라는 용어를 자주 사용한다.
  </li>
    <ul>
      <li>
        대부분의 경우 스트림은 파티션의 수와 상관없이 <strong>토픽 내에 저장된 데이터</strong>로 간주되며, 프로듀서(producer)부터 컨슈머(consumer)로의 <strong>하나의 데이터 흐름</strong>을 나타낸다.
      </li>
      <li>
        메시지의 집합을 스트림이라는 용어로 부르는 것은, 메시지를 시간에 따라 지속적으로 처리하는 <strong>스트림 처리(stream processing)</strong>의 관점에서 논의를 진행할 때 일반적이며, 전통적인 배치 처리(batch processing)와는 구분된다.
      </li>
    </ul>
</ul>

<br>

<h2>2-4. 프로듀서와 컨슈머</h2>