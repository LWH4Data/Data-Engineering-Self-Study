<h1>1. 발행/구독 메시지 전달</h1>
<ul>
  <li>
    <strong>발행/구독 메시지 전달(pubish/subscribe messaging)</strong>과 <strong>데이터 주도 애플리케이션</strong>의 중요성을 이해해야 한다.
  </li>
    <ul>
      <li>
        발행/구독 메시지 전달(publish/subscribe messaging) 패턴의 특징은 데이터를 보낼 때 직접 수신자에게 보내지 않는다. 대신 <strong>전송자</strong>가 메시지를 <strong>분류</strong>해서 보내면 <strong>수신자</strong>는 분류된 메시지를 <strong>구독</strong>한다.
      </li>
    </ul>
  <li>
    발행/구독 시스템에는 대개 발행된 메시지를 전달받고 <strong>중계</strong>해주는 중간 지점 역할을 하는 <strong>브로커(broker)</strong>가 있다.
  </li>
</ul>

<br>

<h2>1-1. 초기의 발행/구독 시스템</h2>
<ul>
  <li>
    많은 발행/구독 패턴을 따르는 사례들은 가운데 간단한 <strong>메시지 큐</strong>나 프로세스 간 <strong>통신 채널</strong>을 놓는 유사한 패턴을 갖는다.
  </li>
  <li>
    중간 단계가 없다면 각 애플리케이션을 개별로 연결하여 데이터를 받아야하며 앱이 추가될 때마다 점점 연결이 복잡해진다. 이때 <strong>모든 애플리케이션으로부터 지표를 받는 하나의 애플리케이션</strong>을 만들고 모든 질의 요청을 처리하게 한다면 개별 앱에 연결해야하는 <strong>복잡성</strong>을 줄일 수 있다.
  </li>
    <ul>
      <li>
        위의 구조가 메시지 발행/구독 시스템이다.
      </li>
    </ul>
</ul>

<br>

<h2>1-2. 개별 메시지 큐 시스템</h2>
<ul>
  <li>
    로그 또한 동일하게 개별 앱으로 요청을 보내는 것이 아니라 중앙의 서버에서 통합적으로 저장하고 모든 요청을 처리하는 발행/구독 시스템을 사용하면 이점이 많다.
  </li>
    <ul>
      <li>
        즉, point-to-point 연결 방식보다 중간 서버를 사용하면 복잡한 연결을 피할 수 있다.
      </li>
      <li>
        단, <strong>중복</strong>이 많을 수 있으며 <strong>버그와 한계가 제각각</strong>인 다수의 데이터 큐 시스템을 유지 관리해야 한다는 문제 등이 존재한다.
      </li>
    </ul>
</ul>

<br><br>

<h1>2. 카프카 입문</h1>
<ul>
  <li>
    앞선 문제를 개선하기 위해 고안된 메시지 발행/구독 시스템이 <strong>Kafka</strong>이다. Kafka는 <strong>분산 커밋 로그</strong> 혹은 <strong>분산 스트리밍 플랫폼</strong>이라고 불리기도 한다.
  </li>
  <li>
    파일시스템이나 데이터베이스 커밋 로그(commit log)는 모든 트랜잭션 기록은 지속성(durable) 있게 보존하여 시스템의 상태를 일관성(consistency) 있게 복구할 수 있도록 고안되었다.
  </li>
    <ul>
      <li>
        <strong>Kafka</strong>는 저장된 데이터의 <strong>순서</strong>를 유지한 채로 <strong>지속성</strong> 있게 보관되며 <strong>결정적(deterministic)</strong>으로 읽을 수 있다.
      </li>
      <li>
        <strong>Kafka</strong>는 <strong>확장</strong>시 성능을 향상시키고 <strong>실패</strong>가 발생하여도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 <strong>분산시켜 저장</strong>할 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>2-1. 메시지와 배치</h2>
<ul>
  <li>
    Kafka에서 데이터의 기본 단위는 <strong>메시지(message)</strong>다.
  </li>
    <ul>
      <li>
        메시지는 DB의 row나 record와 유사해 보일 수 있다.
      </li>
      <li>
        Kafka 입장에서 메시지는 <strong>단순한 바이트의 배열</strong>일 뿐 특정한 형식이나 의미는 없다.
      </li>
    </ul>
  <li>
    메시지는 <strong>키(key)</strong>라 불리는 <strong>메타데이터</strong>를 포함할 수 있다.
  </li>
    <ul>
      <li>
        키 또한 Kafka의 입장에서는 의미가 없는 <strong>바이트 배열</strong>일 뿐이다.
      </li>
      <li>
        키는 메시지를 저장할 <strong>파티션을 결정</strong>하기 위해 사용된다.
      </li>
        <ul>
          <li>
            간단한 방법으로는 <strong>'key에서 생성된 hash 값 %(나머지 연산) 토픽의 파티션 수'</strong>에 해당하는 파티션에 메시지를 저장하는 것이다.
          </li>
        </ul>
    </ul>
  <li>
    Kafka는 효율성을 위해 메시지를 <strong>배치(batch)</strong> 단위로 저장한다.
  </li>
    <ul>
      <li>
        배치란 그저 같은 토픽의 파티션에 쓰여지는 <strong>메시지들의 집합</strong>일 뿐이다.
      </li>
      <li>
        배치는 <strong>지연(latency)</strong>과 <strong>처리량(throughput)</strong> 사이에 <strong>trade-off</strong>를 발생시킨다.
      </li>
        <ul>
          <li>
            배치 크기가 클수록 시간당 처리되는 메시지의 수는 늘어나지만, 각각의 메시지가 전달되는 데 걸리는 시간도 증가한다.
          </li>
        </ul>
      <li>
        배치는 더 효율적인 데이터 전송과 저장을 위해 약간의 처리 능력을 들여서 <strong>압축</strong>되는 경우가 많다.
      </li>
    </ul>
</ul>

<br>

<h2>2-2. 스키마</h2>
<ul>
  <li>
    Kafka에게 있어 메시지는 단순한 바이트 배열이지만, 내용을 이해하기 쉽도록 일정한 <strong>스키마</strong>를 부여하는 것이 권장된다.
  </li>
    <ul>
      <li>
        스키마에는 JSON(JavaScript Object Notation)이나 XML(eXtensilbe Markup Language)등이 있으나 타입 처리 기능이나 호환성 유지 기능이 떨어져 많은 Kafka 개발자들은 <strong>Avro</strong>를 선호한다.
      </li>
        <ul>
          <li>
            Avro는 조밀한 <strong>직렬화 형식</strong>을 제공한다.
          </li>
          <li>
            Avro는 메시지 본체와 스키마를 분리하기에 <strong>스키마가 변경</strong> 되어도 코드를 생성할 필요가 없다.
          </li>
          <li>
            Avro는 강력한 데이터 타이핑(typing)과 스키마 변경에 따른 <strong>상위 호환성</strong>과 <strong>하휘 호환성</strong> 또한 지원한다.
          </li>
        </ul>
    </ul>
  <li>
    Kafka는 메시지 쓰기와 읽기 작업을 분리할 수 있도록 하기위해 <strong>일관적인 데이터 형식</strong>이 중요하다.
  </li>
  <li>
    스키마와 직렬화에 대해서는 3장에서 자세히 다룬다.
  </li>
</ul>

<br>

<h2>2-3. 토픽과 파티션</h2>
<ul>
  <li>
    Kafka에 저장되는 메시지는 <strong>토픽(topic)</strong> 단위로 분류된다.
  </li>
    <ul>
      <li>
        DB의 테이블 혹은 파일시스템의 폴더와 유사하다.
      </li>
    </ul>
  <li>
    토픽은 다시 여러 개의 <strong>파티션(partition)</strong>으로 나뉘어 진다.
  </li>
    <ul>
      <li>
        파티션은 하나의 로그에 해당한다. 이때의 로그는 일반적인 백엔드 서버의 로그가 아니라, 이벤트가 순서대로 append되는 <strong>Kafka의 커밋 로그(commit log)</strong>를 의미한다.
      </li>
      <li>
        파티션에 메시지가 쓰여질 때에는 <strong>추가만 가능(append-only)</strong>한 형태로 쓰여진다.
      </li>
      <li>
        로그를 읽을 때에는 맨 앞부터 제일 끝까지 <strong>순서대로</strong> 읽는다.
      </li>
      <li>
        토픽 안의 여러 파티션 간의 순서는 보장하지 않지만, 각 파티션 내부의 <strong>레코드들의 순서</strong>는 보장된다.
      </li>
      <li>
        각 파티션은 다른 서버에 저장딜 수 있기에 하나의 서버의 용량을 넘어 여러 개의 서버로 <strong>수평적 확장</strong>될 수 있다.
      </li>
      <li>
        파티션은 서로 다른 서버들이 동일한 파티션의 <strong>복제본을 저장</strong>할 수 있기에 <strong>중복</strong>될 수 있다. 따라서 하나의 <strong>서버에 장애</strong>가 발생하여도 대응이 가능하다.
      </li>
    </ul>
  <li>
    Kafka와 같은 시스템을 이야기할 때에는 <strong>스트림(stream)</strong>이라는 용어를 자주 사용한다.
  </li>
    <ul>
      <li>
        대부분의 경우 스트림은 파티션의 수와 상관없이 <strong>토픽 내에 저장된 데이터</strong>로 간주되며, 프로듀서(producer)부터 컨슈머(consumer)로의 <strong>하나의 데이터 흐름</strong>을 나타낸다.
      </li>
      <li>
        메시지의 집합을 스트림이라는 용어로 부르는 것은, 메시지를 시간에 따라 지속적으로 처리하는 <strong>스트림 처리(stream processing)</strong>의 관점에서 논의를 진행할 때 일반적이며, 전통적인 배치 처리(batch processing)와는 구분된다.
      </li>
    </ul>
</ul>

<br>

<h2>2-4. 프로듀서와 컨슈머</h2>
<ul>
  <li>
    Kafka의 클라이언트는 시스템의 사용자이며 기본적으로 <strong>프로듀서</strong>와 <strong>컨슈머</strong> 두 종류가 있다.
  </li>
    <ul>
      <li>
        고급 클라이언트 API로는 데이터 통합에 사용되는 <strong>Kafka Connect</strong>와 스트림 처리에 사용되는 <strong>카프카 스트림즈</strong>가 있다.
      </li>
    </ul>
  <li>
    <strong>프로듀서</strong>
  </li>
    <ul>
      <li>
        프로듀서는 <strong>새로운 메시지를 생성</strong>한다.
      </li>
      <li>
        다른 발행/구독 시스템에서는 <strong>발행자(publisher)</strong> 혹은 <strong>작성자(writer)</strong>라고도 부른다.
      </li>
      <li>
        메시지는 <strong>특정한 토픽</strong>에 쓰인다.
      </li>
        <ul>
          <li>
            기본적으로 프로듀서는 메시지를 쓸 때 토픽에 속한 <strong>파티션들 사이에 고르게 나눠서</strong> 쓰도록 되어있다.
          </li>
          <li>
            특정 경우에는 <strong>특정한 파티션</strong>을 지정하여 메시지를 쓰기도 한다.
          </li>
          <li>
            메시지 쓰기는 대개 메시지 <strong>키</strong>와 키값의 해시를 특정한 파티션으로 대응시켜 주는 <strong>파티셔너(partitioner)</strong>를 사용해 구현된다.
          </li>
            <ul>
              <li>
                이로인해 동일한 키값을 가진 모든 메시지는 같은 파티션에 저장된다.
              </li>
            </ul>
        </ul>
      <li>
        프로듀서는 메시지를 파티션으로 대응시켜 주는 나름의 규칙을 갖는 <strong>커스텀 파티셔너</strong>를 사용할 수도 있다.
      </li>
    </ul>
  <li>
    <strong>컨슈머</strong>
  </li>
    <ul>
      <li>
        컨슈머는 <strong>메시지를 읽는다</strong>.
      </li>
      <li>
        다른 발행/구독 시스템에서는 <strong>구독자(subscriber)</strong> 혹은 <strong>독자(reader)</strong>라고도 한다.
      </li>
      <li>
        컨슈머는 <strong>한 개 이상의 토픽</strong>을 구독하고, 각 토픽에 저장된 메시지들을 <strong>파티션에 쓰여진 순서대로</strong> 읽어온다.
      </li>
      <li>
        컨슈머는 메시지의 <strong>offset</strong>을 기록하여 <strong>어느 메시지까지 읽었는지</strong> 유지한다.
      </li>
        <ul>
          <li>
            Offset은 지속적으로 증가하는 정수값으로, Kafka 메시지를 저장할 때 각각의 <strong>메시지에 부여</strong>하는 또 다른 <strong>메타데이터</strong>이다.
          </li>
          <li>
            각 메시지는 고유한 offset을 갖는다.
          </li>
          <li>
            뒤에오는 메시지는 앞에오는 메시지보다 더 큰 offset을 갖는다. 즉, <strong>오름차순</strong>이나 반드시 <strong>단조 증가일 필요는 없다</strong>.
          </li>
          <li>
            파티션별로 <strong>다음 번에 사용 가능한 오프셋 값</strong>을 저장하여 컨슈머는 읽기 작업을 정지했다가 다시 시작하여도 <strong>마지막으로 읽은 지점</strong>부터 시작할 수 있다.
          </li>
        </ul>
    </ul>
  <li>
    <strong>컨슈머 그룹(consumer group)</strong>
  </li>
    <ul>
      <li>
        컨슈머는 consumer group의 일원으로 작동한다.
      </li>
      <li>
        Consumer group은 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 이루어진다.
      </li>
      <li>
        Consumer group은 각 파티션이 <strong>하나의 컨슈머</strong>에 의해서만 읽히도록 한다.
      </li>
        <ul>
          <li>
            즉, 하나의 컨슈머는 다중 파티션을 읽을 수 있으나 하나의 파티션은 다중 컨슈머에 배정될 수 없다.
          </li>
        </ul>
      <li>
        이처럼 하나의 파티션이 하나의 컨슈머에 배정되는 것을 컨슈머의 <strong>파티션 소유권(ownership)</strong>이라고도 부른다.
      </li>
      <li>
        위와 같은 방법으로 대량의 메시지를 갖는 토픽들을 읽기 위해 <strong>컨슈머들을 수평 확장</strong>할 수 있다. 
      </li>
      <li>
        또한 컨슈머 중 하나에 장애가 생기더라도 해당 컨슈머가 읽고 있던 <strong>파티션을 재할당</strong>하여 작업을 이어갈 수 있다.
      </li>
    </ul>
</ul>

<br>

<h2>2-5. 브로커와 클러스터</h2>
<ul>
  <li>
    하나의 카프카 서버를 <strong>브로커</strong>라고 부른다.
  </li>
    <ul>
      <li>
        브로커는 <strong>프로듀서</strong>로부터 <strong>메시지</strong>를 전달받아 <strong>오프셋</strong>을 할당한 뒤 <strong>저장소</strong>에 쓴다.
      </li>
      <li>
        브로커는 파티션 <strong>읽기(fetch) 요청</strong>을 처리하고 발행된 메시지를 보내준다.
      </li>
    </ul>
  <li>
    카프카 브로커는 <strong>클러스터의 일부</strong>로 작동하도록 설계되었다.
  </li>
    <ul>
      <li>
        하나의 클러스터 내에는 여러 개의 브로커가 포함될 수 있으며, 이 중 하나의 브로커가 <strong>클러스터 컨트롤러</strong> 역할을 한다.
      </li>
        <ul>
          <li>
            컨트롤러는 <strong>파티션을 브로커에게 할당</strong>하거나 장애가 발생한 브로커를 <strong>모니터링</strong>하는 등 <strong>관리 기능</strong>을 담당한다.
          </li>
        </ul>
      <li>
        파티션은 클러스터 안의 브로커 중 하나가 담당하며 해당 브로커를 <strong>파티션 리더(partition leader)</strong>라 한다.
      </li>
        <ul>
          <li>
            복제된 파티션이 여러 브로커에 할당될 수도 있는데 이때 파티션을 할당 받은 프로커를 <strong>팔로워(follwer)</strong>라 한다.
          </li>
          <li>
            <strong>복제(replication)</strong> 기능은 파티션의 메시지를 중복 저장하여 리더 브로커에 <strong>장애가 발생</strong>했을 때 <strong>팔로워 중 하나가 리더</strong>의 역할을 이어받는다.
          </li>
        </ul>
      <li>
        <strong>모든 프로듀서는 리더 브로커</strong>에 메시지를 발행해야 하지만, <strong>컨슈머는 리더나 팔로워 중 하나</strong>로부터 데이터를 읽어올 수 있다.
      </li>
    </ul>
  <li>
    Kafka의 핵심 기능 중에는 일정 기간 동안 메시지를 <strong>지속성(durability)</strong> 있게 보관하는 <strong>보존(retention)</strong> 기능이 있다.
  </li>
    <ul>
      <li>
        Kafka 브로커는 토픽에 대해 기본적인 보존 설정이 되어 있다.
      </li>
        <ul>
          <li>
            특정 기간 동안 메시지를 보존한다.
          </li>
          <li>
            파티션이 크기가 특정 사이즈에 도달할 때까지 데이터를 보존한다.
          </li>
        </ul>
      <li>
        각각의 토픽에는 메시지가 필요한 정도까지만 저정되도록 보존 설정을 잡아 둘 수 있다.
      </li>
    </ul>
  <li>
    토픽에는 로그 <strong>압착(log compaction) 기능</strong>을 설정할 수 있다. 이 경우 같은 키를 갖는 메시지 중 <strong>가장 최신의 것</strong>만 보존된다.
  </li>
    <ul>
      <li>
        해당 기능은 마지막 변경값만이 중요한 <strong>체인지로그(changelog) 형태</strong>의 데이터에 사용하면 좋다.
      </li>
        <ul>
          <li>
            체인지로그란? 어떤 데이터의 상태가 어떻게 바뀌어 왔는지를 시간 순서대로 기록한 로그를 의미한다.
          </li>
        </ul>
    </ul>
</ul>

<br>

<h2>2-6. 다중 클러스터</h2>
<ul>
  <li>
    Kafka가 확장되에 따라 <strong>다수의 클러스터</strong>를 운용하는 것이 더 나은 경우가 있으며 아래와 같은 장점이 있다.
  </li>
    <ul>
      <li>
        데이터 유형별 분리
      </li>
      <li>
        보안 요구사항을 충족시키기 위한 격리
      </li>
      <li>
        재해 복구(disaster recovery, DR)를 대비한 다중 데이터센터
      </li>
    </ul>
  <li>
    특히 Kafka를 다수의 데이터센터에 걸쳐 운용하는 환경, 즉 <strong>멀티 클러스터 환경</strong>에서는 각 데이터센터에 위치한 서로 다른 Kafka 클러스터 간에 메시지를 복제할 필요가 있는 경우가 많다.
  </li>
    <ul>
      <li>
        위의 경우 양쪽 데이터센터에서 모두 정보를 활용할 수 있다. 따라서 어느 데이터센터인지와 무관하게 서비스가 유지된다.
      </li>
      <li>
        혹은 여러 곳의 데이터를 수집한 뒤 하나의 중앙 집결지로 모을 수도 있다.
      </li>
    </ul>
  <li>
    기본적으로 Kafka 클러스터의 복제 메커니즘은 하나의 클러스터 내에서만 작동한다. 따라서 <strong>다수의 클러스터에 복제</strong>를 하기 위해서는 <strong>미러메이커(MirrorMaker)</strong>라는 툴을 사용한다.
  </li>
    <ul>
      <li>
        미러메이커도 사실상 큐로 연결된 카프카 컨슈머와 프로듀서이며 이를 통한 메시지 송수신으로 <strong>복제(Mirroring)</strong>를 하는 것이다.
      </li>
    </ul>
</ul>

<br><br>

<h1>3. 왜 카프카인가?</h1>
<h2>3-1. 다중 프로듀서</h2>
<ul>
  <li>
    Kafka는 <strong>여러 프로듀서</strong>를 처리할 수 있다.
  </li>
    <ul>
      <li>
        많은 프론트엔드 시스템으로부터 데이터를 수집하고 일돤성을 유지할 수 있어 백엔드는 여러 프론트 엔드로부터 데이터를 수집할 필요가 없다.
      </li>
    </ul>
</ul>

<br>

<h2>3-2. 다중 컨슈머</h2>
<ul>
  <li>
    Kafka는 컨슈머가 <strong>상호 간섭 없이</strong> 어떠한 메시지 스트림도 읽을 수 있도록 설계되었다.
  </li>
    <ul>
      <li>
        다수의 카프카 컨슈머는 <strong>컨슈머 그룹</strong>의 일원으로 작동하며 <strong>하나의 스트림을 여럿</strong>이서 나눠서 읽을 수 있다. (메시지는 전체 컨슈머 그룹에 대하 한 번만 처리된다).
      </li>
    </ul>
</ul>

<br>

<h2>3-3. 디스크 기반 보존</h2>
<ul>
  <li>
    Kafka는 메시지를 <strong>디스크</strong>에 설정된 <strong>보유 규칙</strong>과 함께 저장한다.
  </li>
    <ul>
      <li>
        옵션들은 <strong>토픽별로 설정</strong>이 가능하여 서로 다른 메시지 스트림이 컨슈머의 필요에 따라 다르게 보존될 수 있다.
      </li>
      <li>
        만약 컨슈머가 느린 처리 속도 혹은 트래픽 폭주로 뒤쳐진다 해도 메시지는 <strong>디스크</strong>에 저장되어 있기에 문제가 없다.
      </li>
      <li>
        마찬가지로 디스크에 메시지를 저장하고 있기에 프로듀서는 별도로 메시지를 <strong>백업</strong>하거나 <strong>메시지 유실</strong>을 걱정할 필요가 없다.
      </li>
    </ul>
</ul>

<br>

<h2>3-4. 확장성</h2>
<ul>
  <li>
    Kafka는 유연한 확장성을 가지고 있기 때문에 <strong>어떠한 크기의 데이터</strong>도 쉽게 처리할 수 있다.
  </li>
    <ul>
      <li>
        하나의 브로커로 test
        <br>→ 적은 수의 브로커 환경 test
        <br>→ 수십 개에서 수백 개의 브로커로 된 대규모 클러스터에서 test
      </li>
    </ul>
  <li>
    Kafka 클러스터는 작동 중에도 시스템 전체의 <strong>가용성(availability)</strong>에 영향을 주지 않으면서 확장이 가능하다.
  </li>
    <ul>
      <li>
        즉, 개별 브로커의 장애를 처리하는 등의 작업을 하면서 지속적으로 클라이언트의 요청을 처리할 수 있다.
      </li>
      <li>
        동시자발적인 장애를 견뎌야 하는 클러스터의 경우 <strong>더 큰 복제 팩터(replication factork RF)</strong>를 설정해 주는 것이 가능하다.
      </li>
    </ul>
</ul>